{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aa03aa13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Categorical columns: ['Gender', 'self_employed', 'family_history', 'treatment', 'Days_Indoors', 'Growing_Stress', 'Changes_Habits', 'Mental_Health_History', 'Mood_Swings', 'Coping_Struggles', 'Work_Interest', 'Social_Weakness', 'mental_health_interview', 'care_options']\n",
      "\n",
      "=== Training MLP_Simple Model ===\n",
      "Epoch 1/10\n",
      "6579/6579 [==============================] - 2s 346us/step - loss: 1.0266 - accuracy: 0.4738 - val_loss: 0.9480 - val_accuracy: 0.5740\n",
      "Epoch 2/10\n",
      "6579/6579 [==============================] - 2s 337us/step - loss: 0.9593 - accuracy: 0.5423 - val_loss: 0.8871 - val_accuracy: 0.6296\n",
      "Epoch 3/10\n",
      "6579/6579 [==============================] - 2s 332us/step - loss: 0.9314 - accuracy: 0.5618 - val_loss: 0.8584 - val_accuracy: 0.6413\n",
      "Epoch 4/10\n",
      "6579/6579 [==============================] - 2s 329us/step - loss: 0.9176 - accuracy: 0.5687 - val_loss: 0.8379 - val_accuracy: 0.6457\n",
      "Epoch 5/10\n",
      "6579/6579 [==============================] - 2s 329us/step - loss: 0.9052 - accuracy: 0.5754 - val_loss: 0.8221 - val_accuracy: 0.6509\n",
      "Epoch 6/10\n",
      "6579/6579 [==============================] - 2s 337us/step - loss: 0.8936 - accuracy: 0.5818 - val_loss: 0.8029 - val_accuracy: 0.6588\n",
      "Epoch 7/10\n",
      "6579/6579 [==============================] - 2s 330us/step - loss: 0.8792 - accuracy: 0.5873 - val_loss: 0.7809 - val_accuracy: 0.6744\n",
      "Epoch 8/10\n",
      "6579/6579 [==============================] - 2s 340us/step - loss: 0.8695 - accuracy: 0.5904 - val_loss: 0.7719 - val_accuracy: 0.6770\n",
      "Epoch 9/10\n",
      "6579/6579 [==============================] - 2s 331us/step - loss: 0.8651 - accuracy: 0.5904 - val_loss: 0.7640 - val_accuracy: 0.6697\n",
      "Epoch 10/10\n",
      "6579/6579 [==============================] - 2s 331us/step - loss: 0.8610 - accuracy: 0.5931 - val_loss: 0.7578 - val_accuracy: 0.6679\n",
      "1828/1828 [==============================] - 0s 211us/step\n",
      "MLP_Simple - Test Loss: 0.7561, Test Accuracy: 0.6702\n",
      "Confusion Matrix:\n",
      "[[12554  2804  2754]\n",
      " [ 2965 12200  4955]\n",
      " [ 2942  2866 14433]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.69      0.69     18112\n",
      "           1       0.68      0.61      0.64     20120\n",
      "           2       0.65      0.71      0.68     20241\n",
      "\n",
      "    accuracy                           0.67     58473\n",
      "   macro avg       0.67      0.67      0.67     58473\n",
      "weighted avg       0.67      0.67      0.67     58473\n",
      "\n",
      "\n",
      "=== Training MLP_Deep Model ===\n",
      "Epoch 1/10\n",
      "6579/6579 [==============================] - 4s 578us/step - loss: 0.9473 - accuracy: 0.5254 - val_loss: 0.5418 - val_accuracy: 0.7879\n",
      "Epoch 2/10\n",
      "6579/6579 [==============================] - 4s 563us/step - loss: 0.6809 - accuracy: 0.6914 - val_loss: 0.3455 - val_accuracy: 0.8742\n",
      "Epoch 3/10\n",
      "6579/6579 [==============================] - 4s 560us/step - loss: 0.5919 - accuracy: 0.7373 - val_loss: 0.2908 - val_accuracy: 0.8922\n",
      "Epoch 4/10\n",
      "6579/6579 [==============================] - 4s 564us/step - loss: 0.5504 - accuracy: 0.7579 - val_loss: 0.2486 - val_accuracy: 0.8994\n",
      "Epoch 5/10\n",
      "6579/6579 [==============================] - 4s 557us/step - loss: 0.5236 - accuracy: 0.7702 - val_loss: 0.2398 - val_accuracy: 0.8966\n",
      "Epoch 6/10\n",
      "6579/6579 [==============================] - 4s 559us/step - loss: 0.5049 - accuracy: 0.7800 - val_loss: 0.2259 - val_accuracy: 0.9055\n",
      "Epoch 7/10\n",
      "6579/6579 [==============================] - 4s 558us/step - loss: 0.4917 - accuracy: 0.7857 - val_loss: 0.2212 - val_accuracy: 0.9051\n",
      "Epoch 8/10\n",
      "6579/6579 [==============================] - 4s 569us/step - loss: 0.4839 - accuracy: 0.7899 - val_loss: 0.2153 - val_accuracy: 0.9100\n",
      "Epoch 9/10\n",
      "6579/6579 [==============================] - 4s 558us/step - loss: 0.4760 - accuracy: 0.7945 - val_loss: 0.2063 - val_accuracy: 0.9136\n",
      "Epoch 10/10\n",
      "6579/6579 [==============================] - 4s 557us/step - loss: 0.4685 - accuracy: 0.7975 - val_loss: 0.2071 - val_accuracy: 0.9136\n",
      "1828/1828 [==============================] - 0s 251us/step\n",
      "MLP_Deep - Test Loss: 0.2054, Test Accuracy: 0.9145\n",
      "Confusion Matrix:\n",
      "[[16527   665   920]\n",
      " [  668 18236  1216]\n",
      " [  711   818 18712]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.91      0.92     18112\n",
      "           1       0.92      0.91      0.92     20120\n",
      "           2       0.90      0.92      0.91     20241\n",
      "\n",
      "    accuracy                           0.91     58473\n",
      "   macro avg       0.92      0.91      0.91     58473\n",
      "weighted avg       0.91      0.91      0.91     58473\n",
      "\n",
      "\n",
      "=== Training CNN Model ===\n",
      "Epoch 1/10\n",
      "6579/6579 [==============================] - 3s 492us/step - loss: 1.0886 - accuracy: 0.3823 - val_loss: 1.0782 - val_accuracy: 0.4126\n",
      "Epoch 2/10\n",
      "6579/6579 [==============================] - 3s 466us/step - loss: 1.0653 - accuracy: 0.4168 - val_loss: 1.0449 - val_accuracy: 0.4460\n",
      "Epoch 3/10\n",
      "6579/6579 [==============================] - 3s 495us/step - loss: 1.0379 - accuracy: 0.4442 - val_loss: 1.0170 - val_accuracy: 0.4661\n",
      "Epoch 4/10\n",
      "6579/6579 [==============================] - 3s 478us/step - loss: 1.0115 - accuracy: 0.4647 - val_loss: 0.9862 - val_accuracy: 0.4850\n",
      "Epoch 5/10\n",
      "6579/6579 [==============================] - 3s 465us/step - loss: 0.9874 - accuracy: 0.4809 - val_loss: 0.9564 - val_accuracy: 0.5183\n",
      "Epoch 6/10\n",
      "6579/6579 [==============================] - 3s 462us/step - loss: 0.9653 - accuracy: 0.4929 - val_loss: 0.9309 - val_accuracy: 0.5260\n",
      "Epoch 7/10\n",
      "6579/6579 [==============================] - 3s 476us/step - loss: 0.9435 - accuracy: 0.5046 - val_loss: 0.9014 - val_accuracy: 0.5419\n",
      "Epoch 8/10\n",
      "6579/6579 [==============================] - 3s 465us/step - loss: 0.9249 - accuracy: 0.5155 - val_loss: 0.8806 - val_accuracy: 0.5593\n",
      "Epoch 9/10\n",
      "6579/6579 [==============================] - 3s 467us/step - loss: 0.9101 - accuracy: 0.5239 - val_loss: 0.8492 - val_accuracy: 0.5735\n",
      "Epoch 10/10\n",
      "6579/6579 [==============================] - 3s 474us/step - loss: 0.8962 - accuracy: 0.5309 - val_loss: 0.8405 - val_accuracy: 0.5878\n",
      "1828/1828 [==============================] - 0s 234us/step\n",
      "CNN - Test Loss: 0.8408, Test Accuracy: 0.5872\n",
      "Confusion Matrix:\n",
      "[[10083  1474  6555]\n",
      " [ 3205  8981  7934]\n",
      " [ 2808  2160 15273]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.56      0.59     18112\n",
      "           1       0.71      0.45      0.55     20120\n",
      "           2       0.51      0.75      0.61     20241\n",
      "\n",
      "    accuracy                           0.59     58473\n",
      "   macro avg       0.62      0.59      0.58     58473\n",
      "weighted avg       0.62      0.59      0.58     58473\n",
      "\n",
      "\n",
      "=== Training LSTM Model ===\n",
      "Epoch 1/10\n",
      "6579/6579 [==============================] - 15s 2ms/step - loss: 1.0760 - accuracy: 0.3892 - val_loss: 1.0565 - val_accuracy: 0.4142\n",
      "Epoch 2/10\n",
      "6579/6579 [==============================] - 14s 2ms/step - loss: 0.8788 - accuracy: 0.5481 - val_loss: 0.4992 - val_accuracy: 0.7731\n",
      "Epoch 3/10\n",
      "6579/6579 [==============================] - 14s 2ms/step - loss: 0.4079 - accuracy: 0.8052 - val_loss: 0.2450 - val_accuracy: 0.8737\n",
      "Epoch 4/10\n",
      "6579/6579 [==============================] - 16s 2ms/step - loss: 0.2614 - accuracy: 0.8687 - val_loss: 0.1813 - val_accuracy: 0.9033\n",
      "Epoch 5/10\n",
      "6579/6579 [==============================] - 16s 2ms/step - loss: 0.2010 - accuracy: 0.8988 - val_loss: 0.1356 - val_accuracy: 0.9241\n",
      "Epoch 6/10\n",
      "6579/6579 [==============================] - 16s 2ms/step - loss: 0.1538 - accuracy: 0.9208 - val_loss: 0.1088 - val_accuracy: 0.9373\n",
      "Epoch 7/10\n",
      "6579/6579 [==============================] - 16s 2ms/step - loss: 0.1283 - accuracy: 0.9315 - val_loss: 0.1001 - val_accuracy: 0.9405\n",
      "Epoch 8/10\n",
      "6579/6579 [==============================] - 16s 2ms/step - loss: 0.1136 - accuracy: 0.9373 - val_loss: 0.0873 - val_accuracy: 0.9450\n",
      "Epoch 9/10\n",
      "6579/6579 [==============================] - 16s 2ms/step - loss: 0.1054 - accuracy: 0.9403 - val_loss: 0.0824 - val_accuracy: 0.9457\n",
      "Epoch 10/10\n",
      "6579/6579 [==============================] - 16s 2ms/step - loss: 0.1006 - accuracy: 0.9414 - val_loss: 0.0880 - val_accuracy: 0.9423\n",
      "1828/1828 [==============================] - 1s 709us/step\n",
      "LSTM - Test Loss: 0.0869, Test Accuracy: 0.9440\n",
      "Confusion Matrix:\n",
      "[[17096   649   367]\n",
      " [  126 18827  1167]\n",
      " [  732   234 19275]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.94      0.95     18112\n",
      "           1       0.96      0.94      0.95     20120\n",
      "           2       0.93      0.95      0.94     20241\n",
      "\n",
      "    accuracy                           0.94     58473\n",
      "   macro avg       0.94      0.94      0.94     58473\n",
      "weighted avg       0.94      0.94      0.94     58473\n",
      "\n",
      "\n",
      "=== Overall Model Performance ===\n",
      "MLP_Simple: Accuracy = 0.6702\n",
      "MLP_Deep: Accuracy = 0.9145\n",
      "CNN: Accuracy = 0.5872\n",
      "LSTM: Accuracy = 0.9440\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization, Conv1D, GlobalMaxPooling1D, LSTM\n",
    "\n",
    "# === 1. Data Preprocessing ===\n",
    "\n",
    "# Load the dataset\n",
    "file_path = \"Mental Health Dataset.csv\"\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Drop irrelevant columns (adjust as needed)\n",
    "df = df.drop(columns=['Timestamp', 'Country', 'Occupation'])\n",
    "\n",
    "# Fill missing values using the mode for each column\n",
    "df = df.fillna(df.mode().iloc[0])\n",
    "\n",
    "# Identify all categorical columns\n",
    "categorical_cols = df.select_dtypes(include=['object']).columns.tolist()\n",
    "print(\"Categorical columns:\", categorical_cols)\n",
    "\n",
    "# Encode all categorical columns using LabelEncoder\n",
    "label_encoders = {}\n",
    "for col in categorical_cols:\n",
    "    le = LabelEncoder()\n",
    "    df[col] = le.fit_transform(df[col])\n",
    "    label_encoders[col] = le\n",
    "\n",
    "# Separate features and target (target is \"Mood_Swings\")\n",
    "X = df.drop(columns=['Mood_Swings'])\n",
    "y = df['Mood_Swings']\n",
    "\n",
    "# Split the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Standardize the features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# For CNN and LSTM models, reshape data as a sequence (each feature as a \"time step\")\n",
    "num_features = X_train_scaled.shape[1]\n",
    "X_train_seq = X_train_scaled.reshape(-1, num_features, 1)\n",
    "X_test_seq = X_test_scaled.reshape(-1, num_features, 1)\n",
    "\n",
    "# Determine the number of classes for output layer\n",
    "num_classes = len(np.unique(y))\n",
    "\n",
    "# === 2. Define Deep Learning Models ===\n",
    "\n",
    "# Model 1: Simple MLP\n",
    "def build_mlp_model_simple(input_dim):\n",
    "    model = Sequential([\n",
    "        Dense(64, activation='relu', input_dim=input_dim),\n",
    "        Dropout(0.3),\n",
    "        Dense(num_classes, activation='softmax')\n",
    "    ])\n",
    "    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Model 2: Deep MLP with Batch Normalization\n",
    "def build_mlp_model_deep(input_dim):\n",
    "    model = Sequential([\n",
    "        Dense(128, activation='relu', input_dim=input_dim),\n",
    "        BatchNormalization(),\n",
    "        Dropout(0.4),\n",
    "        Dense(64, activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        Dropout(0.3),\n",
    "        Dense(32, activation='relu'),\n",
    "        Dense(num_classes, activation='softmax')\n",
    "    ])\n",
    "    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Model 3: CNN Model (1D convolution)\n",
    "def build_cnn_model(input_shape):\n",
    "    model = Sequential([\n",
    "        Conv1D(64, kernel_size=3, activation='relu', input_shape=input_shape),\n",
    "        GlobalMaxPooling1D(),\n",
    "        Dense(64, activation='relu'),\n",
    "        Dropout(0.3),\n",
    "        Dense(num_classes, activation='softmax')\n",
    "    ])\n",
    "    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Model 4: LSTM Model (treat features as a sequence)\n",
    "def build_lstm_model(input_shape):\n",
    "    model = Sequential([\n",
    "        LSTM(64, input_shape=input_shape),\n",
    "        Dropout(0.3),\n",
    "        Dense(64, activation='relu'),\n",
    "        Dropout(0.2),\n",
    "        Dense(num_classes, activation='softmax')\n",
    "    ])\n",
    "    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# === 3. Train and Evaluate Models ===\n",
    "\n",
    "models = {\n",
    "    \"MLP_Simple\": build_mlp_model_simple(X_train_scaled.shape[1]),\n",
    "    \"MLP_Deep\": build_mlp_model_deep(X_train_scaled.shape[1]),\n",
    "    \"CNN\": build_cnn_model((num_features, 1)),\n",
    "    \"LSTM\": build_lstm_model((num_features, 1))\n",
    "}\n",
    "\n",
    "results = {}\n",
    "\n",
    "for model_name, model in models.items():\n",
    "    print(f\"\\n=== Training {model_name} Model ===\")\n",
    "    \n",
    "    if model_name in [\"CNN\", \"LSTM\"]:\n",
    "        history = model.fit(X_train_seq, y_train, epochs=10, batch_size=32,\n",
    "                            validation_split=0.1, verbose=1)\n",
    "        loss, acc = model.evaluate(X_test_seq, y_test, verbose=0)\n",
    "        y_pred_probs = model.predict(X_test_seq)\n",
    "    else:\n",
    "        history = model.fit(X_train_scaled, y_train, epochs=10, batch_size=32,\n",
    "                            validation_split=0.1, verbose=1)\n",
    "        loss, acc = model.evaluate(X_test_scaled, y_test, verbose=0)\n",
    "        y_pred_probs = model.predict(X_test_scaled)\n",
    "    \n",
    "    # Convert predicted probabilities to class labels\n",
    "    y_pred = np.argmax(y_pred_probs, axis=1)\n",
    "    \n",
    "    # Generate confusion matrix and classification report\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    report = classification_report(y_test, y_pred)\n",
    "    \n",
    "    print(f\"{model_name} - Test Loss: {loss:.4f}, Test Accuracy: {acc:.4f}\")\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(cm)\n",
    "    print(\"Classification Report:\")\n",
    "    print(report)\n",
    "    \n",
    "    results[model_name] = {\n",
    "        \"loss\": loss,\n",
    "        \"accuracy\": acc,\n",
    "        \"confusion_matrix\": cm,\n",
    "        \"classification_report\": report\n",
    "    }\n",
    "\n",
    "# === 4. Model Performance Comparison ===\n",
    "\n",
    "print(\"\\n=== Overall Model Performance ===\")\n",
    "for model_name, metrics in results.items():\n",
    "    print(f\"{model_name}: Accuracy = {metrics['accuracy']:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8b73d037",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Categorical columns: ['Gender', 'self_employed', 'family_history', 'treatment', 'Days_Indoors', 'Growing_Stress', 'Changes_Habits', 'Mental_Health_History', 'Mood_Swings', 'Coping_Struggles', 'Work_Interest', 'Social_Weakness', 'mental_health_interview', 'care_options']\n",
      "\n",
      "=== Training MLP_Simple Model ===\n",
      "Epoch 1/20\n",
      "6579/6579 [==============================] - 2s 351us/step - loss: 1.0296 - accuracy: 0.4706 - val_loss: 0.9517 - val_accuracy: 0.5573\n",
      "Epoch 2/20\n",
      "6579/6579 [==============================] - 2s 331us/step - loss: 0.9601 - accuracy: 0.5362 - val_loss: 0.8898 - val_accuracy: 0.6273\n",
      "Epoch 3/20\n",
      "6579/6579 [==============================] - 2s 342us/step - loss: 0.9254 - accuracy: 0.5587 - val_loss: 0.8471 - val_accuracy: 0.6380\n",
      "Epoch 4/20\n",
      "6579/6579 [==============================] - 2s 333us/step - loss: 0.9009 - accuracy: 0.5712 - val_loss: 0.8119 - val_accuracy: 0.6560\n",
      "Epoch 5/20\n",
      "6579/6579 [==============================] - 2s 335us/step - loss: 0.8800 - accuracy: 0.5840 - val_loss: 0.7828 - val_accuracy: 0.6850\n",
      "Epoch 6/20\n",
      "6579/6579 [==============================] - 2s 333us/step - loss: 0.8587 - accuracy: 0.5929 - val_loss: 0.7528 - val_accuracy: 0.6924\n",
      "Epoch 7/20\n",
      "6579/6579 [==============================] - 2s 334us/step - loss: 0.8445 - accuracy: 0.5991 - val_loss: 0.7348 - val_accuracy: 0.6872\n",
      "Epoch 8/20\n",
      "6579/6579 [==============================] - 2s 333us/step - loss: 0.8363 - accuracy: 0.5984 - val_loss: 0.7194 - val_accuracy: 0.6958\n",
      "Epoch 9/20\n",
      "6579/6579 [==============================] - 2s 331us/step - loss: 0.8274 - accuracy: 0.6046 - val_loss: 0.7093 - val_accuracy: 0.6903\n",
      "Epoch 10/20\n",
      "6579/6579 [==============================] - 2s 333us/step - loss: 0.8228 - accuracy: 0.6080 - val_loss: 0.7023 - val_accuracy: 0.7044\n",
      "Epoch 11/20\n",
      "6579/6579 [==============================] - 2s 334us/step - loss: 0.8195 - accuracy: 0.6085 - val_loss: 0.6980 - val_accuracy: 0.7081\n",
      "Epoch 12/20\n",
      "6579/6579 [==============================] - 2s 333us/step - loss: 0.8142 - accuracy: 0.6109 - val_loss: 0.6913 - val_accuracy: 0.7129\n",
      "Epoch 13/20\n",
      "6579/6579 [==============================] - 2s 333us/step - loss: 0.8093 - accuracy: 0.6107 - val_loss: 0.6839 - val_accuracy: 0.7143\n",
      "Epoch 14/20\n",
      "6579/6579 [==============================] - 2s 356us/step - loss: 0.8074 - accuracy: 0.6148 - val_loss: 0.6781 - val_accuracy: 0.7165\n",
      "Epoch 15/20\n",
      "6579/6579 [==============================] - 2s 338us/step - loss: 0.8042 - accuracy: 0.6158 - val_loss: 0.6779 - val_accuracy: 0.7184\n",
      "Epoch 16/20\n",
      "6579/6579 [==============================] - 2s 333us/step - loss: 0.8020 - accuracy: 0.6166 - val_loss: 0.6734 - val_accuracy: 0.7114\n",
      "Epoch 17/20\n",
      "6579/6579 [==============================] - 2s 346us/step - loss: 0.7986 - accuracy: 0.6202 - val_loss: 0.6701 - val_accuracy: 0.7189\n",
      "Epoch 18/20\n",
      "6579/6579 [==============================] - 2s 369us/step - loss: 0.7960 - accuracy: 0.6192 - val_loss: 0.6685 - val_accuracy: 0.7285\n",
      "Epoch 19/20\n",
      "6579/6579 [==============================] - 2s 358us/step - loss: 0.7942 - accuracy: 0.6191 - val_loss: 0.6606 - val_accuracy: 0.7282\n",
      "Epoch 20/20\n",
      "6579/6579 [==============================] - 2s 343us/step - loss: 0.7934 - accuracy: 0.6206 - val_loss: 0.6621 - val_accuracy: 0.7191\n",
      "1828/1828 [==============================] - 0s 204us/step\n",
      "MLP_Simple - Test Accuracy: 0.7151\n",
      "Confusion Matrix:\n",
      "[[14050  2882  1180]\n",
      " [ 2722 14558  2840]\n",
      " [ 3168  3865 13208]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.78      0.74     18112\n",
      "           1       0.68      0.72      0.70     20120\n",
      "           2       0.77      0.65      0.71     20241\n",
      "\n",
      "    accuracy                           0.72     58473\n",
      "   macro avg       0.72      0.72      0.72     58473\n",
      "weighted avg       0.72      0.72      0.71     58473\n",
      "\n",
      "\n",
      "=== Training MLP_Deep Model ===\n",
      "Epoch 1/20\n",
      "6579/6579 [==============================] - 4s 588us/step - loss: 0.9242 - accuracy: 0.5418 - val_loss: 0.5156 - val_accuracy: 0.7956\n",
      "Epoch 2/20\n",
      "6579/6579 [==============================] - 4s 582us/step - loss: 0.6667 - accuracy: 0.7016 - val_loss: 0.3386 - val_accuracy: 0.8841\n",
      "Epoch 3/20\n",
      "6579/6579 [==============================] - 4s 603us/step - loss: 0.5810 - accuracy: 0.7441 - val_loss: 0.2821 - val_accuracy: 0.8859\n",
      "Epoch 4/20\n",
      "6579/6579 [==============================] - 4s 590us/step - loss: 0.5412 - accuracy: 0.7631 - val_loss: 0.2626 - val_accuracy: 0.8932\n",
      "Epoch 5/20\n",
      "6579/6579 [==============================] - 4s 591us/step - loss: 0.5149 - accuracy: 0.7748 - val_loss: 0.2487 - val_accuracy: 0.8955\n",
      "Epoch 6/20\n",
      "6579/6579 [==============================] - 4s 585us/step - loss: 0.4985 - accuracy: 0.7818 - val_loss: 0.2386 - val_accuracy: 0.8940\n",
      "Epoch 7/20\n",
      "6579/6579 [==============================] - 4s 585us/step - loss: 0.4869 - accuracy: 0.7879 - val_loss: 0.2314 - val_accuracy: 0.8965\n",
      "Epoch 8/20\n",
      "6579/6579 [==============================] - 4s 603us/step - loss: 0.4771 - accuracy: 0.7918 - val_loss: 0.2282 - val_accuracy: 0.9005\n",
      "Epoch 9/20\n",
      "6579/6579 [==============================] - 4s 597us/step - loss: 0.4672 - accuracy: 0.7961 - val_loss: 0.2233 - val_accuracy: 0.9004\n",
      "Epoch 10/20\n",
      "6579/6579 [==============================] - 4s 576us/step - loss: 0.4593 - accuracy: 0.8007 - val_loss: 0.2192 - val_accuracy: 0.9021\n",
      "Epoch 11/20\n",
      "6579/6579 [==============================] - 4s 584us/step - loss: 0.4513 - accuracy: 0.8032 - val_loss: 0.2227 - val_accuracy: 0.8987\n",
      "Epoch 12/20\n",
      "6579/6579 [==============================] - 4s 574us/step - loss: 0.4488 - accuracy: 0.8058 - val_loss: 0.2146 - val_accuracy: 0.9044\n",
      "Epoch 13/20\n",
      "6579/6579 [==============================] - 4s 578us/step - loss: 0.4399 - accuracy: 0.8087 - val_loss: 0.2108 - val_accuracy: 0.9041\n",
      "Epoch 14/20\n",
      "6579/6579 [==============================] - 4s 579us/step - loss: 0.4383 - accuracy: 0.8100 - val_loss: 0.2068 - val_accuracy: 0.9012\n",
      "Epoch 15/20\n",
      "6579/6579 [==============================] - 4s 585us/step - loss: 0.4312 - accuracy: 0.8124 - val_loss: 0.2057 - val_accuracy: 0.9031\n",
      "Epoch 16/20\n",
      "6579/6579 [==============================] - 4s 575us/step - loss: 0.4294 - accuracy: 0.8136 - val_loss: 0.2004 - val_accuracy: 0.9055\n",
      "Epoch 17/20\n",
      "6579/6579 [==============================] - 4s 593us/step - loss: 0.4278 - accuracy: 0.8142 - val_loss: 0.2028 - val_accuracy: 0.9048\n",
      "Epoch 18/20\n",
      "6579/6579 [==============================] - 4s 590us/step - loss: 0.4211 - accuracy: 0.8176 - val_loss: 0.1983 - val_accuracy: 0.9089\n",
      "Epoch 19/20\n",
      "6579/6579 [==============================] - 4s 590us/step - loss: 0.4193 - accuracy: 0.8189 - val_loss: 0.1979 - val_accuracy: 0.9082\n",
      "Epoch 20/20\n",
      "6579/6579 [==============================] - 4s 587us/step - loss: 0.4154 - accuracy: 0.8209 - val_loss: 0.2014 - val_accuracy: 0.9051\n",
      "1828/1828 [==============================] - 1s 273us/step\n",
      "MLP_Deep - Test Accuracy: 0.9062\n",
      "Confusion Matrix:\n",
      "[[16831   690   591]\n",
      " [  948 17937  1235]\n",
      " [ 1258   760 18223]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.93      0.91     18112\n",
      "           1       0.93      0.89      0.91     20120\n",
      "           2       0.91      0.90      0.90     20241\n",
      "\n",
      "    accuracy                           0.91     58473\n",
      "   macro avg       0.91      0.91      0.91     58473\n",
      "weighted avg       0.91      0.91      0.91     58473\n",
      "\n",
      "\n",
      "=== Training CNN Model ===\n",
      "Epoch 1/20\n",
      "6579/6579 [==============================] - 3s 504us/step - loss: 1.0895 - accuracy: 0.3816 - val_loss: 1.0799 - val_accuracy: 0.3963\n",
      "Epoch 2/20\n",
      "6579/6579 [==============================] - 3s 498us/step - loss: 1.0707 - accuracy: 0.4124 - val_loss: 1.0501 - val_accuracy: 0.4422\n",
      "Epoch 3/20\n",
      "6579/6579 [==============================] - 3s 482us/step - loss: 1.0446 - accuracy: 0.4413 - val_loss: 1.0194 - val_accuracy: 0.4732\n",
      "Epoch 4/20\n",
      "6579/6579 [==============================] - 3s 530us/step - loss: 1.0186 - accuracy: 0.4644 - val_loss: 0.9975 - val_accuracy: 0.4857\n",
      "Epoch 5/20\n",
      "6579/6579 [==============================] - 3s 489us/step - loss: 0.9975 - accuracy: 0.4788 - val_loss: 0.9739 - val_accuracy: 0.5034\n",
      "Epoch 6/20\n",
      "6579/6579 [==============================] - 3s 475us/step - loss: 0.9768 - accuracy: 0.4918 - val_loss: 0.9394 - val_accuracy: 0.5230\n",
      "Epoch 7/20\n",
      "6579/6579 [==============================] - 3s 513us/step - loss: 0.9580 - accuracy: 0.5040 - val_loss: 0.9149 - val_accuracy: 0.5504\n",
      "Epoch 8/20\n",
      "6579/6579 [==============================] - 3s 472us/step - loss: 0.9396 - accuracy: 0.5134 - val_loss: 0.9146 - val_accuracy: 0.5431\n",
      "Epoch 9/20\n",
      "6579/6579 [==============================] - 3s 469us/step - loss: 0.9252 - accuracy: 0.5200 - val_loss: 0.8857 - val_accuracy: 0.5483\n",
      "Epoch 10/20\n",
      "6579/6579 [==============================] - 3s 469us/step - loss: 0.9118 - accuracy: 0.5257 - val_loss: 0.8748 - val_accuracy: 0.5627\n",
      "Epoch 11/20\n",
      "6579/6579 [==============================] - 3s 474us/step - loss: 0.9001 - accuracy: 0.5289 - val_loss: 0.8655 - val_accuracy: 0.5731\n",
      "Epoch 12/20\n",
      "6579/6579 [==============================] - 3s 481us/step - loss: 0.8889 - accuracy: 0.5341 - val_loss: 0.8354 - val_accuracy: 0.5858\n",
      "Epoch 13/20\n",
      "6579/6579 [==============================] - 3s 480us/step - loss: 0.8810 - accuracy: 0.5370 - val_loss: 0.8157 - val_accuracy: 0.5959\n",
      "Epoch 14/20\n",
      "6579/6579 [==============================] - 3s 496us/step - loss: 0.8705 - accuracy: 0.5433 - val_loss: 0.8190 - val_accuracy: 0.5923\n",
      "Epoch 15/20\n",
      "6579/6579 [==============================] - 3s 489us/step - loss: 0.8634 - accuracy: 0.5442 - val_loss: 0.8112 - val_accuracy: 0.5894\n",
      "Epoch 16/20\n",
      "6579/6579 [==============================] - 3s 480us/step - loss: 0.8554 - accuracy: 0.5480 - val_loss: 0.7930 - val_accuracy: 0.6054\n",
      "Epoch 17/20\n",
      "6579/6579 [==============================] - 3s 462us/step - loss: 0.8462 - accuracy: 0.5522 - val_loss: 0.7824 - val_accuracy: 0.6004\n",
      "Epoch 18/20\n",
      "6579/6579 [==============================] - 3s 472us/step - loss: 0.8381 - accuracy: 0.5538 - val_loss: 0.7556 - val_accuracy: 0.6192\n",
      "Epoch 19/20\n",
      "6579/6579 [==============================] - 3s 476us/step - loss: 0.8320 - accuracy: 0.5563 - val_loss: 0.7696 - val_accuracy: 0.6108\n",
      "Epoch 20/20\n",
      "6579/6579 [==============================] - 3s 477us/step - loss: 0.8229 - accuracy: 0.5602 - val_loss: 0.7484 - val_accuracy: 0.6236\n",
      "1828/1828 [==============================] - 0s 233us/step\n",
      "CNN - Test Accuracy: 0.6247\n",
      "Confusion Matrix:\n",
      "[[ 9849   812  7451]\n",
      " [ 1969  9579  8572]\n",
      " [ 1417  1723 17101]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.54      0.63     18112\n",
      "           1       0.79      0.48      0.59     20120\n",
      "           2       0.52      0.84      0.64     20241\n",
      "\n",
      "    accuracy                           0.62     58473\n",
      "   macro avg       0.68      0.62      0.62     58473\n",
      "weighted avg       0.68      0.62      0.62     58473\n",
      "\n",
      "\n",
      "=== Training LSTM Model ===\n",
      "Epoch 1/20\n",
      "6579/6579 [==============================] - 15s 2ms/step - loss: 1.0757 - accuracy: 0.3889 - val_loss: 1.0564 - val_accuracy: 0.4110\n",
      "Epoch 2/20\n",
      "6579/6579 [==============================] - 15s 2ms/step - loss: 0.9054 - accuracy: 0.5322 - val_loss: 0.5906 - val_accuracy: 0.7274\n",
      "Epoch 3/20\n",
      "6579/6579 [==============================] - 15s 2ms/step - loss: 0.4312 - accuracy: 0.7941 - val_loss: 0.2586 - val_accuracy: 0.8653\n",
      "Epoch 4/20\n",
      "6579/6579 [==============================] - 15s 2ms/step - loss: 0.2722 - accuracy: 0.8620 - val_loss: 0.2082 - val_accuracy: 0.8900\n",
      "Epoch 5/20\n",
      "6579/6579 [==============================] - 15s 2ms/step - loss: 0.2050 - accuracy: 0.8953 - val_loss: 0.1573 - val_accuracy: 0.9211\n",
      "Epoch 6/20\n",
      "6579/6579 [==============================] - 15s 2ms/step - loss: 0.1500 - accuracy: 0.9230 - val_loss: 0.1022 - val_accuracy: 0.9401\n",
      "Epoch 7/20\n",
      "6579/6579 [==============================] - 15s 2ms/step - loss: 0.1214 - accuracy: 0.9344 - val_loss: 0.0962 - val_accuracy: 0.9417\n",
      "Epoch 8/20\n",
      "6579/6579 [==============================] - 15s 2ms/step - loss: 0.1123 - accuracy: 0.9379 - val_loss: 0.0822 - val_accuracy: 0.9449\n",
      "Epoch 9/20\n",
      "6579/6579 [==============================] - 15s 2ms/step - loss: 0.1031 - accuracy: 0.9407 - val_loss: 0.0825 - val_accuracy: 0.9456\n",
      "Epoch 10/20\n",
      "6579/6579 [==============================] - 15s 2ms/step - loss: 0.0987 - accuracy: 0.9421 - val_loss: 0.0814 - val_accuracy: 0.9449\n",
      "Epoch 11/20\n",
      "6579/6579 [==============================] - 15s 2ms/step - loss: 0.0962 - accuracy: 0.9421 - val_loss: 0.0798 - val_accuracy: 0.9464\n",
      "Epoch 12/20\n",
      "6579/6579 [==============================] - 15s 2ms/step - loss: 0.0949 - accuracy: 0.9426 - val_loss: 0.0797 - val_accuracy: 0.9460\n",
      "Epoch 13/20\n",
      "6579/6579 [==============================] - 15s 2ms/step - loss: 0.0942 - accuracy: 0.9429 - val_loss: 0.0795 - val_accuracy: 0.9457\n",
      "Epoch 14/20\n",
      "6579/6579 [==============================] - 15s 2ms/step - loss: 0.0913 - accuracy: 0.9427 - val_loss: 0.0796 - val_accuracy: 0.9469\n",
      "Epoch 15/20\n",
      "6579/6579 [==============================] - 15s 2ms/step - loss: 0.0907 - accuracy: 0.9438 - val_loss: 0.0813 - val_accuracy: 0.9463\n",
      "Epoch 16/20\n",
      "6579/6579 [==============================] - 15s 2ms/step - loss: 0.0897 - accuracy: 0.9435 - val_loss: 0.0788 - val_accuracy: 0.9449\n",
      "Epoch 17/20\n",
      "6579/6579 [==============================] - 15s 2ms/step - loss: 0.0891 - accuracy: 0.9446 - val_loss: 0.0789 - val_accuracy: 0.9473\n",
      "Epoch 18/20\n",
      "6579/6579 [==============================] - 15s 2ms/step - loss: 0.0880 - accuracy: 0.9443 - val_loss: 0.1128 - val_accuracy: 0.9402\n",
      "Epoch 19/20\n",
      "6579/6579 [==============================] - 15s 2ms/step - loss: 0.0897 - accuracy: 0.9445 - val_loss: 0.0803 - val_accuracy: 0.9461\n",
      "Epoch 20/20\n",
      "6579/6579 [==============================] - 15s 2ms/step - loss: 0.0861 - accuracy: 0.9451 - val_loss: 0.0783 - val_accuracy: 0.9454\n",
      "1828/1828 [==============================] - 1s 722us/step\n",
      "LSTM - Test Accuracy: 0.9479\n",
      "Confusion Matrix:\n",
      "[[16404   622  1086]\n",
      " [   23 19936   161]\n",
      " [    6  1148 19087]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.91      0.95     18112\n",
      "           1       0.92      0.99      0.95     20120\n",
      "           2       0.94      0.94      0.94     20241\n",
      "\n",
      "    accuracy                           0.95     58473\n",
      "   macro avg       0.95      0.95      0.95     58473\n",
      "weighted avg       0.95      0.95      0.95     58473\n",
      "\n",
      "\n",
      "=== Training BiLSTM Model ===\n",
      "Epoch 1/20\n",
      "6579/6579 [==============================] - 19s 3ms/step - loss: 1.0805 - accuracy: 0.3906 - val_loss: 1.0247 - val_accuracy: 0.4584\n",
      "Epoch 2/20\n",
      "6579/6579 [==============================] - 210s 32ms/step - loss: 0.8489 - accuracy: 0.5777 - val_loss: 0.4986 - val_accuracy: 0.7820\n",
      "Epoch 3/20\n",
      "6579/6579 [==============================] - 17s 3ms/step - loss: 0.4575 - accuracy: 0.7853 - val_loss: 0.2841 - val_accuracy: 0.8587\n",
      "Epoch 4/20\n",
      "6579/6579 [==============================] - 17s 3ms/step - loss: 0.3333 - accuracy: 0.8374 - val_loss: 0.2347 - val_accuracy: 0.8735\n",
      "Epoch 5/20\n",
      "6579/6579 [==============================] - 17s 3ms/step - loss: 0.2852 - accuracy: 0.8583 - val_loss: 0.2078 - val_accuracy: 0.8893\n",
      "Epoch 6/20\n",
      "6579/6579 [==============================] - 17s 3ms/step - loss: 0.2524 - accuracy: 0.8752 - val_loss: 0.1810 - val_accuracy: 0.9055\n",
      "Epoch 7/20\n",
      "6579/6579 [==============================] - 17s 3ms/step - loss: 0.2259 - accuracy: 0.8874 - val_loss: 0.1618 - val_accuracy: 0.9126\n",
      "Epoch 8/20\n",
      "6579/6579 [==============================] - 17s 3ms/step - loss: 0.2088 - accuracy: 0.8967 - val_loss: 0.1479 - val_accuracy: 0.9212\n",
      "Epoch 9/20\n",
      "6579/6579 [==============================] - 17s 3ms/step - loss: 0.1884 - accuracy: 0.9062 - val_loss: 0.1429 - val_accuracy: 0.9233\n",
      "Epoch 10/20\n",
      "6579/6579 [==============================] - 17s 3ms/step - loss: 0.1725 - accuracy: 0.9130 - val_loss: 0.1222 - val_accuracy: 0.9332\n",
      "Epoch 11/20\n",
      "6579/6579 [==============================] - 17s 3ms/step - loss: 0.1588 - accuracy: 0.9191 - val_loss: 0.1199 - val_accuracy: 0.9351\n",
      "Epoch 12/20\n",
      "6579/6579 [==============================] - 17s 3ms/step - loss: 0.1483 - accuracy: 0.9239 - val_loss: 0.1028 - val_accuracy: 0.9395\n",
      "Epoch 13/20\n",
      "6579/6579 [==============================] - 17s 3ms/step - loss: 0.1356 - accuracy: 0.9277 - val_loss: 0.0981 - val_accuracy: 0.9417\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/20\n",
      "6579/6579 [==============================] - 16s 2ms/step - loss: 0.1307 - accuracy: 0.9298 - val_loss: 0.0912 - val_accuracy: 0.9416\n",
      "Epoch 15/20\n",
      "6579/6579 [==============================] - 16s 2ms/step - loss: 0.1247 - accuracy: 0.9328 - val_loss: 0.0902 - val_accuracy: 0.9419\n",
      "Epoch 16/20\n",
      "6579/6579 [==============================] - 16s 2ms/step - loss: 0.1196 - accuracy: 0.9348 - val_loss: 0.0846 - val_accuracy: 0.9430\n",
      "Epoch 17/20\n",
      "6579/6579 [==============================] - 17s 3ms/step - loss: 0.1135 - accuracy: 0.9365 - val_loss: 0.0874 - val_accuracy: 0.9436\n",
      "Epoch 18/20\n",
      "6579/6579 [==============================] - 16s 2ms/step - loss: 0.1099 - accuracy: 0.9380 - val_loss: 0.0833 - val_accuracy: 0.9450\n",
      "Epoch 19/20\n",
      "6579/6579 [==============================] - 16s 2ms/step - loss: 0.1065 - accuracy: 0.9389 - val_loss: 0.0858 - val_accuracy: 0.9439\n",
      "Epoch 20/20\n",
      "6579/6579 [==============================] - 17s 3ms/step - loss: 0.1051 - accuracy: 0.9393 - val_loss: 0.0813 - val_accuracy: 0.9457\n",
      "1828/1828 [==============================] - 2s 790us/step\n",
      "BiLSTM - Test Accuracy: 0.9468\n",
      "Confusion Matrix:\n",
      "[[16478   648   986]\n",
      " [   31 19819   270]\n",
      " [  106  1071 19064]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.91      0.95     18112\n",
      "           1       0.92      0.99      0.95     20120\n",
      "           2       0.94      0.94      0.94     20241\n",
      "\n",
      "    accuracy                           0.95     58473\n",
      "   macro avg       0.95      0.95      0.95     58473\n",
      "weighted avg       0.95      0.95      0.95     58473\n",
      "\n",
      "\n",
      "=== Training CNN_LSTM Model ===\n",
      "Epoch 1/20\n",
      "6579/6579 [==============================] - 19s 3ms/step - loss: 0.8033 - accuracy: 0.5904 - val_loss: 0.2852 - val_accuracy: 0.8581\n",
      "Epoch 2/20\n",
      "6579/6579 [==============================] - 18s 3ms/step - loss: 0.2744 - accuracy: 0.8649 - val_loss: 0.1912 - val_accuracy: 0.9039\n",
      "Epoch 3/20\n",
      "6579/6579 [==============================] - 18s 3ms/step - loss: 0.1784 - accuracy: 0.9108 - val_loss: 0.1075 - val_accuracy: 0.9381\n",
      "Epoch 4/20\n",
      "6579/6579 [==============================] - 18s 3ms/step - loss: 0.1252 - accuracy: 0.9339 - val_loss: 0.0899 - val_accuracy: 0.9446\n",
      "Epoch 5/20\n",
      "6579/6579 [==============================] - 17s 3ms/step - loss: 0.1091 - accuracy: 0.9390 - val_loss: 0.0846 - val_accuracy: 0.9452\n",
      "Epoch 6/20\n",
      "6579/6579 [==============================] - 18s 3ms/step - loss: 0.0986 - accuracy: 0.9417 - val_loss: 0.0810 - val_accuracy: 0.9467\n",
      "Epoch 7/20\n",
      "6579/6579 [==============================] - 18s 3ms/step - loss: 0.0971 - accuracy: 0.9419 - val_loss: 0.0799 - val_accuracy: 0.9464\n",
      "Epoch 8/20\n",
      "6579/6579 [==============================] - 22s 3ms/step - loss: 0.0944 - accuracy: 0.9434 - val_loss: 0.0801 - val_accuracy: 0.9460\n",
      "Epoch 9/20\n",
      "6579/6579 [==============================] - 18s 3ms/step - loss: 0.0917 - accuracy: 0.9435 - val_loss: 0.0788 - val_accuracy: 0.9458\n",
      "Epoch 10/20\n",
      "6579/6579 [==============================] - 18s 3ms/step - loss: 0.0899 - accuracy: 0.9436 - val_loss: 0.0793 - val_accuracy: 0.9465\n",
      "Epoch 11/20\n",
      "6579/6579 [==============================] - 18s 3ms/step - loss: 0.0894 - accuracy: 0.9436 - val_loss: 0.0831 - val_accuracy: 0.9455\n",
      "Epoch 12/20\n",
      "6579/6579 [==============================] - 18s 3ms/step - loss: 0.0877 - accuracy: 0.9451 - val_loss: 0.0826 - val_accuracy: 0.9452\n",
      "Epoch 13/20\n",
      "6579/6579 [==============================] - 18s 3ms/step - loss: 0.0877 - accuracy: 0.9440 - val_loss: 0.0790 - val_accuracy: 0.9470\n",
      "Epoch 14/20\n",
      "6579/6579 [==============================] - 18s 3ms/step - loss: 0.0875 - accuracy: 0.9449 - val_loss: 0.0788 - val_accuracy: 0.9459\n",
      "Epoch 15/20\n",
      "6579/6579 [==============================] - 18s 3ms/step - loss: 0.0872 - accuracy: 0.9441 - val_loss: 0.0786 - val_accuracy: 0.9455\n",
      "Epoch 16/20\n",
      "6579/6579 [==============================] - 18s 3ms/step - loss: 0.0864 - accuracy: 0.9440 - val_loss: 0.0783 - val_accuracy: 0.9462\n",
      "Epoch 17/20\n",
      "6579/6579 [==============================] - 18s 3ms/step - loss: 0.0849 - accuracy: 0.9450 - val_loss: 0.0806 - val_accuracy: 0.9466\n",
      "Epoch 18/20\n",
      "6579/6579 [==============================] - 18s 3ms/step - loss: 0.0852 - accuracy: 0.9460 - val_loss: 0.0825 - val_accuracy: 0.9459\n",
      "Epoch 19/20\n",
      "6579/6579 [==============================] - 18s 3ms/step - loss: 0.0856 - accuracy: 0.9450 - val_loss: 0.0781 - val_accuracy: 0.9475\n",
      "Epoch 20/20\n",
      "6579/6579 [==============================] - 18s 3ms/step - loss: 0.0844 - accuracy: 0.9449 - val_loss: 0.0793 - val_accuracy: 0.9456\n",
      "1828/1828 [==============================] - 2s 824us/step\n",
      "CNN_LSTM - Test Accuracy: 0.9466\n",
      "Confusion Matrix:\n",
      "[[16484   520  1108]\n",
      " [  111 18709  1300]\n",
      " [    1    81 20159]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.91      0.95     18112\n",
      "           1       0.97      0.93      0.95     20120\n",
      "           2       0.89      1.00      0.94     20241\n",
      "\n",
      "    accuracy                           0.95     58473\n",
      "   macro avg       0.95      0.95      0.95     58473\n",
      "weighted avg       0.95      0.95      0.95     58473\n",
      "\n",
      "\n",
      "=== Training Transformer Model ===\n",
      "Epoch 1/20\n",
      "6579/6579 [==============================] - 10s 2ms/step - loss: 1.1029 - accuracy: 0.3396 - val_loss: 1.0983 - val_accuracy: 0.3440\n",
      "Epoch 2/20\n",
      "6579/6579 [==============================] - 9s 1ms/step - loss: 1.0983 - accuracy: 0.3439 - val_loss: 1.0988 - val_accuracy: 0.3370\n",
      "Epoch 3/20\n",
      "6579/6579 [==============================] - 9s 1ms/step - loss: 1.0978 - accuracy: 0.3447 - val_loss: 1.0983 - val_accuracy: 0.3370\n",
      "Epoch 4/20\n",
      "6579/6579 [==============================] - 9s 1ms/step - loss: 1.0978 - accuracy: 0.3449 - val_loss: 1.0984 - val_accuracy: 0.3370\n",
      "Epoch 5/20\n",
      "6579/6579 [==============================] - 9s 1ms/step - loss: 1.0978 - accuracy: 0.3451 - val_loss: 1.0983 - val_accuracy: 0.3370\n",
      "Epoch 6/20\n",
      "6579/6579 [==============================] - 9s 1ms/step - loss: 1.0977 - accuracy: 0.3452 - val_loss: 1.0986 - val_accuracy: 0.3440\n",
      "Epoch 7/20\n",
      "6579/6579 [==============================] - 9s 1ms/step - loss: 1.0978 - accuracy: 0.3448 - val_loss: 1.0983 - val_accuracy: 0.3370\n",
      "Epoch 8/20\n",
      "6579/6579 [==============================] - 9s 1ms/step - loss: 1.0978 - accuracy: 0.3453 - val_loss: 1.0984 - val_accuracy: 0.3370\n",
      "Epoch 9/20\n",
      "6579/6579 [==============================] - 11s 2ms/step - loss: 1.0978 - accuracy: 0.3451 - val_loss: 1.0987 - val_accuracy: 0.3370\n",
      "Epoch 10/20\n",
      "6579/6579 [==============================] - 9s 1ms/step - loss: 1.0978 - accuracy: 0.3454 - val_loss: 1.0985 - val_accuracy: 0.3370\n",
      "Epoch 11/20\n",
      "6579/6579 [==============================] - 9s 1ms/step - loss: 1.0978 - accuracy: 0.3441 - val_loss: 1.0983 - val_accuracy: 0.3370\n",
      "Epoch 12/20\n",
      "6579/6579 [==============================] - 9s 1ms/step - loss: 1.0977 - accuracy: 0.3454 - val_loss: 1.0983 - val_accuracy: 0.3440\n",
      "Epoch 13/20\n",
      "6579/6579 [==============================] - 9s 1ms/step - loss: 1.0977 - accuracy: 0.3449 - val_loss: 1.0982 - val_accuracy: 0.3370\n",
      "Epoch 14/20\n",
      "6579/6579 [==============================] - 9s 1ms/step - loss: 1.0978 - accuracy: 0.3446 - val_loss: 1.0982 - val_accuracy: 0.3440\n",
      "Epoch 15/20\n",
      "6579/6579 [==============================] - 9s 1ms/step - loss: 1.0978 - accuracy: 0.3442 - val_loss: 1.0985 - val_accuracy: 0.3370\n",
      "Epoch 16/20\n",
      "6579/6579 [==============================] - 9s 1ms/step - loss: 1.0978 - accuracy: 0.3459 - val_loss: 1.0982 - val_accuracy: 0.3370\n",
      "Epoch 17/20\n",
      "6579/6579 [==============================] - 9s 1ms/step - loss: 1.0977 - accuracy: 0.3449 - val_loss: 1.0985 - val_accuracy: 0.3370\n",
      "Epoch 18/20\n",
      "6579/6579 [==============================] - 9s 1ms/step - loss: 1.0978 - accuracy: 0.3457 - val_loss: 1.0982 - val_accuracy: 0.3370\n",
      "Epoch 19/20\n",
      "6579/6579 [==============================] - 9s 1ms/step - loss: 1.0977 - accuracy: 0.3444 - val_loss: 1.0982 - val_accuracy: 0.3440\n",
      "Epoch 20/20\n",
      "6579/6579 [==============================] - 9s 1ms/step - loss: 1.0978 - accuracy: 0.3450 - val_loss: 1.0984 - val_accuracy: 0.3370\n",
      "1828/1828 [==============================] - 1s 618us/step\n",
      "Transformer - Test Accuracy: 0.3462\n",
      "Confusion Matrix:\n",
      "[[    0     0 18112]\n",
      " [    0     0 20120]\n",
      " [    0     0 20241]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00     18112\n",
      "           1       0.00      0.00      0.00     20120\n",
      "           2       0.35      1.00      0.51     20241\n",
      "\n",
      "    accuracy                           0.35     58473\n",
      "   macro avg       0.12      0.33      0.17     58473\n",
      "weighted avg       0.12      0.35      0.18     58473\n",
      "\n",
      "\n",
      "=== Training TCN Model ===\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/vamsipusapati/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/vamsipusapati/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/vamsipusapati/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6579/6579 [==============================] - 74s 11ms/step - loss: 0.4505 - accuracy: 0.7857 - val_loss: 0.1455 - val_accuracy: 0.9267\n",
      "Epoch 2/20\n",
      "6579/6579 [==============================] - 52s 8ms/step - loss: 0.1271 - accuracy: 0.9347 - val_loss: 0.1010 - val_accuracy: 0.9420\n",
      "Epoch 3/20\n",
      "6579/6579 [==============================] - 52s 8ms/step - loss: 0.1025 - accuracy: 0.9415 - val_loss: 0.0836 - val_accuracy: 0.9443\n",
      "Epoch 4/20\n",
      "6579/6579 [==============================] - 52s 8ms/step - loss: 0.0954 - accuracy: 0.9430 - val_loss: 0.0882 - val_accuracy: 0.9446\n",
      "Epoch 5/20\n",
      "6579/6579 [==============================] - 50s 8ms/step - loss: 0.0904 - accuracy: 0.9447 - val_loss: 0.0883 - val_accuracy: 0.9445\n",
      "Epoch 6/20\n",
      "6579/6579 [==============================] - 51s 8ms/step - loss: 0.0893 - accuracy: 0.9442 - val_loss: 0.0816 - val_accuracy: 0.9448\n",
      "Epoch 7/20\n",
      "6579/6579 [==============================] - 52s 8ms/step - loss: 0.0889 - accuracy: 0.9443 - val_loss: 0.0847 - val_accuracy: 0.9439\n",
      "Epoch 8/20\n",
      "6579/6579 [==============================] - 262s 40ms/step - loss: 0.0880 - accuracy: 0.9449 - val_loss: 0.0923 - val_accuracy: 0.9434\n",
      "Epoch 9/20\n",
      "6579/6579 [==============================] - 49s 8ms/step - loss: 0.0873 - accuracy: 0.9452 - val_loss: 0.0799 - val_accuracy: 0.9463\n",
      "Epoch 10/20\n",
      "6579/6579 [==============================] - 48s 7ms/step - loss: 0.0866 - accuracy: 0.9449 - val_loss: 0.0798 - val_accuracy: 0.9454\n",
      "Epoch 11/20\n",
      "6579/6579 [==============================] - 151s 23ms/step - loss: 0.0850 - accuracy: 0.9454 - val_loss: 0.0790 - val_accuracy: 0.9464\n",
      "Epoch 12/20\n",
      "6579/6579 [==============================] - 55s 8ms/step - loss: 0.0867 - accuracy: 0.9452 - val_loss: 0.0807 - val_accuracy: 0.9455\n",
      "Epoch 13/20\n",
      "6579/6579 [==============================] - 53s 8ms/step - loss: 0.0847 - accuracy: 0.9454 - val_loss: 0.0805 - val_accuracy: 0.9447\n",
      "Epoch 14/20\n",
      "6579/6579 [==============================] - 45s 7ms/step - loss: 0.0858 - accuracy: 0.9446 - val_loss: 0.0911 - val_accuracy: 0.9448\n",
      "Epoch 15/20\n",
      "6579/6579 [==============================] - 46s 7ms/step - loss: 0.0849 - accuracy: 0.9454 - val_loss: 0.0794 - val_accuracy: 0.9468\n",
      "Epoch 16/20\n",
      "6579/6579 [==============================] - 51s 8ms/step - loss: 0.0877 - accuracy: 0.9446 - val_loss: 0.0789 - val_accuracy: 0.9471\n",
      "Epoch 17/20\n",
      "6579/6579 [==============================] - 51s 8ms/step - loss: 0.0864 - accuracy: 0.9450 - val_loss: 0.0828 - val_accuracy: 0.9452\n",
      "Epoch 18/20\n",
      "6579/6579 [==============================] - 49s 8ms/step - loss: 0.0848 - accuracy: 0.9452 - val_loss: 0.0803 - val_accuracy: 0.9456\n",
      "Epoch 19/20\n",
      "6579/6579 [==============================] - 50s 8ms/step - loss: 0.0850 - accuracy: 0.9455 - val_loss: 0.0804 - val_accuracy: 0.9467\n",
      "Epoch 20/20\n",
      "6579/6579 [==============================] - 66s 10ms/step - loss: 0.0866 - accuracy: 0.9452 - val_loss: 0.0801 - val_accuracy: 0.9450\n",
      "1828/1828 [==============================] - 4s 2ms/step\n",
      "TCN - Test Accuracy: 0.9478\n",
      "Confusion Matrix:\n",
      "[[16963   281   868]\n",
      " [  395 19693    32]\n",
      " [  207  1267 18767]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.94      0.95     18112\n",
      "           1       0.93      0.98      0.95     20120\n",
      "           2       0.95      0.93      0.94     20241\n",
      "\n",
      "    accuracy                           0.95     58473\n",
      "   macro avg       0.95      0.95      0.95     58473\n",
      "weighted avg       0.95      0.95      0.95     58473\n",
      "\n",
      "\n",
      "=== Training Autoencoder Model ===\n",
      "Epoch 1/20\n",
      "6579/6579 [==============================] - 4s 572us/step - loss: 0.7769 - reconstruction_loss: 0.1462 - classifier_loss: 0.7038 - classifier_accuracy: 0.6803 - val_loss: 0.4439 - val_reconstruction_loss: 0.1009 - val_classifier_loss: 0.3934 - val_classifier_accuracy: 0.8415\n",
      "Epoch 2/20\n",
      "6579/6579 [==============================] - 4s 564us/step - loss: 0.3062 - reconstruction_loss: 0.0761 - classifier_loss: 0.2682 - classifier_accuracy: 0.8974 - val_loss: 0.2517 - val_reconstruction_loss: 0.0555 - val_classifier_loss: 0.2240 - val_classifier_accuracy: 0.9115\n",
      "Epoch 3/20\n",
      "6579/6579 [==============================] - 4s 564us/step - loss: 0.2175 - reconstruction_loss: 0.0452 - classifier_loss: 0.1949 - classifier_accuracy: 0.9192 - val_loss: 0.2147 - val_reconstruction_loss: 0.0384 - val_classifier_loss: 0.1955 - val_classifier_accuracy: 0.9204\n",
      "Epoch 4/20\n",
      "6579/6579 [==============================] - 4s 566us/step - loss: 0.1883 - reconstruction_loss: 0.0343 - classifier_loss: 0.1711 - classifier_accuracy: 0.9280 - val_loss: 0.1734 - val_reconstruction_loss: 0.0322 - val_classifier_loss: 0.1573 - val_classifier_accuracy: 0.9236\n",
      "Epoch 5/20\n",
      "6579/6579 [==============================] - 4s 565us/step - loss: 0.1706 - reconstruction_loss: 0.0289 - classifier_loss: 0.1562 - classifier_accuracy: 0.9340 - val_loss: 0.1613 - val_reconstruction_loss: 0.0270 - val_classifier_loss: 0.1478 - val_classifier_accuracy: 0.9381\n",
      "Epoch 6/20\n",
      "6579/6579 [==============================] - 4s 568us/step - loss: 0.1609 - reconstruction_loss: 0.0237 - classifier_loss: 0.1490 - classifier_accuracy: 0.9366 - val_loss: 0.1508 - val_reconstruction_loss: 0.0230 - val_classifier_loss: 0.1393 - val_classifier_accuracy: 0.9419\n",
      "Epoch 7/20\n",
      "6579/6579 [==============================] - 4s 566us/step - loss: 0.1534 - reconstruction_loss: 0.0188 - classifier_loss: 0.1439 - classifier_accuracy: 0.9379 - val_loss: 0.1396 - val_reconstruction_loss: 0.0167 - val_classifier_loss: 0.1313 - val_classifier_accuracy: 0.9400\n",
      "Epoch 8/20\n",
      "6579/6579 [==============================] - 4s 565us/step - loss: 0.1486 - reconstruction_loss: 0.0162 - classifier_loss: 0.1405 - classifier_accuracy: 0.9390 - val_loss: 0.1403 - val_reconstruction_loss: 0.0167 - val_classifier_loss: 0.1320 - val_classifier_accuracy: 0.9410\n",
      "Epoch 9/20\n",
      "6579/6579 [==============================] - 4s 565us/step - loss: 0.1441 - reconstruction_loss: 0.0155 - classifier_loss: 0.1364 - classifier_accuracy: 0.9408 - val_loss: 0.1335 - val_reconstruction_loss: 0.0126 - val_classifier_loss: 0.1272 - val_classifier_accuracy: 0.9417\n",
      "Epoch 10/20\n",
      "6579/6579 [==============================] - 4s 565us/step - loss: 0.1403 - reconstruction_loss: 0.0132 - classifier_loss: 0.1337 - classifier_accuracy: 0.9411 - val_loss: 0.1483 - val_reconstruction_loss: 0.0114 - val_classifier_loss: 0.1426 - val_classifier_accuracy: 0.9349\n",
      "Epoch 11/20\n",
      "6579/6579 [==============================] - 4s 566us/step - loss: 0.1375 - reconstruction_loss: 0.0122 - classifier_loss: 0.1314 - classifier_accuracy: 0.9418 - val_loss: 0.1287 - val_reconstruction_loss: 0.0118 - val_classifier_loss: 0.1227 - val_classifier_accuracy: 0.9409\n",
      "Epoch 12/20\n",
      "6579/6579 [==============================] - 4s 566us/step - loss: 0.1351 - reconstruction_loss: 0.0112 - classifier_loss: 0.1295 - classifier_accuracy: 0.9420 - val_loss: 0.1227 - val_reconstruction_loss: 0.0104 - val_classifier_loss: 0.1175 - val_classifier_accuracy: 0.9431\n",
      "Epoch 13/20\n",
      "6579/6579 [==============================] - 4s 565us/step - loss: 0.1330 - reconstruction_loss: 0.0107 - classifier_loss: 0.1276 - classifier_accuracy: 0.9428 - val_loss: 0.1234 - val_reconstruction_loss: 0.0097 - val_classifier_loss: 0.1186 - val_classifier_accuracy: 0.9456\n",
      "Epoch 14/20\n",
      "6579/6579 [==============================] - 4s 567us/step - loss: 0.1320 - reconstruction_loss: 0.0111 - classifier_loss: 0.1265 - classifier_accuracy: 0.9420 - val_loss: 0.1138 - val_reconstruction_loss: 0.0112 - val_classifier_loss: 0.1082 - val_classifier_accuracy: 0.9445\n",
      "Epoch 15/20\n",
      "6579/6579 [==============================] - 4s 565us/step - loss: 0.1291 - reconstruction_loss: 0.0099 - classifier_loss: 0.1241 - classifier_accuracy: 0.9430 - val_loss: 0.1210 - val_reconstruction_loss: 0.0090 - val_classifier_loss: 0.1165 - val_classifier_accuracy: 0.9445\n",
      "Epoch 16/20\n",
      "6579/6579 [==============================] - 4s 565us/step - loss: 0.1279 - reconstruction_loss: 0.0096 - classifier_loss: 0.1231 - classifier_accuracy: 0.9428 - val_loss: 0.1284 - val_reconstruction_loss: 0.0102 - val_classifier_loss: 0.1233 - val_classifier_accuracy: 0.9421\n",
      "Epoch 17/20\n",
      "6579/6579 [==============================] - 4s 556us/step - loss: 0.1272 - reconstruction_loss: 0.0098 - classifier_loss: 0.1223 - classifier_accuracy: 0.9434 - val_loss: 0.1264 - val_reconstruction_loss: 0.0080 - val_classifier_loss: 0.1224 - val_classifier_accuracy: 0.9467\n",
      "Epoch 18/20\n",
      "6579/6579 [==============================] - 4s 556us/step - loss: 0.1247 - reconstruction_loss: 0.0093 - classifier_loss: 0.1201 - classifier_accuracy: 0.9436 - val_loss: 0.1180 - val_reconstruction_loss: 0.0089 - val_classifier_loss: 0.1136 - val_classifier_accuracy: 0.9458\n",
      "Epoch 19/20\n",
      "6579/6579 [==============================] - 4s 557us/step - loss: 0.1254 - reconstruction_loss: 0.0103 - classifier_loss: 0.1203 - classifier_accuracy: 0.9436 - val_loss: 0.1317 - val_reconstruction_loss: 0.0087 - val_classifier_loss: 0.1274 - val_classifier_accuracy: 0.9435\n",
      "Epoch 20/20\n",
      "6579/6579 [==============================] - 4s 557us/step - loss: 0.1230 - reconstruction_loss: 0.0089 - classifier_loss: 0.1185 - classifier_accuracy: 0.9438 - val_loss: 0.1184 - val_reconstruction_loss: 0.0080 - val_classifier_loss: 0.1144 - val_classifier_accuracy: 0.9442\n",
      "1828/1828 [==============================] - 0s 257us/step\n",
      "Autoencoder - Test Classifier Accuracy: 0.9459\n",
      "Confusion Matrix:\n",
      "[[17100   440   572]\n",
      " [  227 19057   836]\n",
      " [  523   566 19152]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.94      0.95     18112\n",
      "           1       0.95      0.95      0.95     20120\n",
      "           2       0.93      0.95      0.94     20241\n",
      "\n",
      "    accuracy                           0.95     58473\n",
      "   macro avg       0.95      0.95      0.95     58473\n",
      "weighted avg       0.95      0.95      0.95     58473\n",
      "\n",
      "\n",
      "=== Overall Model Performance ===\n",
      "MLP_Simple: Accuracy = 0.7151\n",
      "MLP_Deep: Accuracy = 0.9062\n",
      "CNN: Accuracy = 0.6247\n",
      "LSTM: Accuracy = 0.9479\n",
      "BiLSTM: Accuracy = 0.9468\n",
      "CNN_LSTM: Accuracy = 0.9466\n",
      "Transformer: Accuracy = 0.3462\n",
      "TCN: Accuracy = 0.9478\n",
      "Autoencoder: Accuracy = 0.9459\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization, Conv1D, GlobalMaxPooling1D, LSTM\n",
    "\n",
    "# ===== 1. Data Preprocessing =====\n",
    "\n",
    "# Load the dataset\n",
    "file_path = \"Mental Health Dataset.csv\"\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Drop irrelevant columns (adjust as needed)\n",
    "df = df.drop(columns=['Timestamp', 'Country', 'Occupation'])\n",
    "\n",
    "# Fill missing values with the mode of each column\n",
    "df = df.fillna(df.mode().iloc[0])\n",
    "\n",
    "# Identify categorical columns (all columns are object type here)\n",
    "categorical_cols = df.select_dtypes(include=['object']).columns.tolist()\n",
    "print(\"Categorical columns:\", categorical_cols)\n",
    "\n",
    "# Encode all categorical columns using LabelEncoder\n",
    "label_encoders = {}\n",
    "for col in categorical_cols:\n",
    "    le = LabelEncoder()\n",
    "    df[col] = le.fit_transform(df[col])\n",
    "    label_encoders[col] = le\n",
    "\n",
    "# Separate features and target (target: 'Mood_Swings')\n",
    "X = df.drop(columns=['Mood_Swings'])\n",
    "y = df['Mood_Swings']\n",
    "\n",
    "# Split data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Standardize features (for models that use flat input)\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# For sequence-based models, reshape to 3D: (samples, timesteps, channels)\n",
    "# Here we treat each feature as a time step (channels=1)\n",
    "num_features = X_train_scaled.shape[1]\n",
    "X_train_seq = X_train_scaled.reshape(-1, num_features, 1)\n",
    "X_test_seq = X_test_scaled.reshape(-1, num_features, 1)\n",
    "\n",
    "# Determine number of classes from the target\n",
    "num_classes = len(np.unique(y))\n",
    "\n",
    "# ===== 2. Define Advanced Deep Learning Models =====\n",
    "\n",
    "# Model 1: Simple MLP\n",
    "def build_mlp_model_simple(input_dim):\n",
    "    model = Sequential([\n",
    "        Dense(64, activation='relu', input_dim=input_dim),\n",
    "        Dropout(0.3),\n",
    "        Dense(num_classes, activation='softmax')\n",
    "    ])\n",
    "    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Model 2: Deep MLP with Batch Normalization\n",
    "def build_mlp_model_deep(input_dim):\n",
    "    model = Sequential([\n",
    "        Dense(128, activation='relu', input_dim=input_dim),\n",
    "        BatchNormalization(),\n",
    "        Dropout(0.4),\n",
    "        Dense(64, activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        Dropout(0.3),\n",
    "        Dense(32, activation='relu'),\n",
    "        Dense(num_classes, activation='softmax')\n",
    "    ])\n",
    "    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Model 3: CNN Model (1D convolution)\n",
    "def build_cnn_model(input_shape):\n",
    "    model = Sequential([\n",
    "        Conv1D(64, kernel_size=3, activation='relu', input_shape=input_shape),\n",
    "        GlobalMaxPooling1D(),\n",
    "        Dense(64, activation='relu'),\n",
    "        Dropout(0.3),\n",
    "        Dense(num_classes, activation='softmax')\n",
    "    ])\n",
    "    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Model 4: LSTM Model (treat features as a sequence)\n",
    "def build_lstm_model(input_shape):\n",
    "    model = Sequential([\n",
    "        LSTM(64, input_shape=input_shape),\n",
    "        Dropout(0.3),\n",
    "        Dense(64, activation='relu'),\n",
    "        Dropout(0.2),\n",
    "        Dense(num_classes, activation='softmax')\n",
    "    ])\n",
    "    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# --- BiLSTM Model ---\n",
    "def build_bilstm_model(input_shape):\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64, return_sequences=True), input_shape=input_shape),\n",
    "        tf.keras.layers.GlobalMaxPooling1D(),\n",
    "        tf.keras.layers.Dropout(0.3),\n",
    "        tf.keras.layers.Dense(64, activation='relu'),\n",
    "        tf.keras.layers.Dropout(0.2),\n",
    "        tf.keras.layers.Dense(num_classes, activation='softmax')\n",
    "    ])\n",
    "    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# --- CNN-LSTM Model ---\n",
    "def build_cnn_lstm_model(input_shape):\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Conv1D(filters=64, kernel_size=3, activation='relu', input_shape=input_shape),\n",
    "        tf.keras.layers.LSTM(64),\n",
    "        tf.keras.layers.Dropout(0.3),\n",
    "        tf.keras.layers.Dense(64, activation='relu'),\n",
    "        tf.keras.layers.Dropout(0.2),\n",
    "        tf.keras.layers.Dense(num_classes, activation='softmax')\n",
    "    ])\n",
    "    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# --- Transformer Model ---\n",
    "def build_transformer_model(input_shape):\n",
    "    inputs = tf.keras.Input(shape=input_shape)\n",
    "    # Multi-head attention\n",
    "    attn_output = tf.keras.layers.MultiHeadAttention(num_heads=2, key_dim=32)(inputs, inputs)\n",
    "    attn_output = tf.keras.layers.Add()([inputs, attn_output])  # Residual connection\n",
    "    attn_output = tf.keras.layers.LayerNormalization(epsilon=1e-6)(attn_output)\n",
    "    # Feed-forward network\n",
    "    ff = tf.keras.layers.Dense(64, activation='relu')(attn_output)\n",
    "    ff = tf.keras.layers.Dense(64)(ff)\n",
    "    ff = tf.keras.layers.Add()([attn_output, ff])\n",
    "    ff = tf.keras.layers.LayerNormalization(epsilon=1e-6)(ff)\n",
    "    pooled = tf.keras.layers.GlobalAveragePooling1D()(ff)\n",
    "    outputs = tf.keras.layers.Dense(num_classes, activation='softmax')(pooled)\n",
    "    model = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
    "    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# --- TCN Model ---\n",
    "def build_tcn_model(input_shape):\n",
    "    from tcn import TCN  # Ensure keras-tcn is installed: pip install keras-tcn\n",
    "    model = tf.keras.Sequential([\n",
    "        TCN(64, input_shape=input_shape),\n",
    "        tf.keras.layers.Dropout(0.3),\n",
    "        tf.keras.layers.Dense(64, activation='relu'),\n",
    "        tf.keras.layers.Dense(num_classes, activation='softmax')\n",
    "    ])\n",
    "    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# --- Supervised Autoencoder Model ---\n",
    "# This model jointly learns to reconstruct the input and to classify it.\n",
    "def build_supervised_autoencoder(input_dim):\n",
    "    inputs = tf.keras.Input(shape=(input_dim,))\n",
    "    encoded = tf.keras.layers.Dense(64, activation='relu', name=\"enc1\")(inputs)\n",
    "    encoded = tf.keras.layers.Dense(32, activation='relu', name=\"enc2\")(encoded)\n",
    "    bottleneck = tf.keras.layers.Dense(16, activation='relu', name='bottleneck')(encoded)\n",
    "    # Decoder branch for reconstruction\n",
    "    decoded = tf.keras.layers.Dense(32, activation='relu', name=\"dec1\")(bottleneck)\n",
    "    decoded = tf.keras.layers.Dense(64, activation='relu', name=\"dec2\")(decoded)\n",
    "    reconstruction = tf.keras.layers.Dense(input_dim, activation='linear', name=\"reconstruction\")(decoded)\n",
    "    # Classification branch from bottleneck features\n",
    "    classifier_output = tf.keras.layers.Dense(num_classes, activation='softmax', name='classifier')(bottleneck)\n",
    "    \n",
    "    model = tf.keras.Model(inputs=inputs, outputs=[reconstruction, classifier_output])\n",
    "    model.compile(optimizer='adam', \n",
    "                  loss={'reconstruction': 'mse', 'classifier': 'sparse_categorical_crossentropy'},\n",
    "                  loss_weights={'reconstruction': 0.5, 'classifier': 1.0},\n",
    "                  metrics={'classifier': 'accuracy'})\n",
    "    return model\n",
    "\n",
    "# ===== 3. Train and Evaluate Each Model =====\n",
    "\n",
    "# Create a dictionary of models with appropriate input shapes.\n",
    "# For sequence-based models, we use the 3D data (X_train_seq).\n",
    "# For the autoencoder, we use the flat standardized data.\n",
    "models = {\n",
    "    \"MLP_Simple\": build_mlp_model_simple(X_train_scaled.shape[1]),\n",
    "    \"MLP_Deep\": build_mlp_model_deep(X_train_scaled.shape[1]),\n",
    "    \"CNN\": build_cnn_model((num_features, 1)),\n",
    "    \"LSTM\": build_lstm_model((num_features, 1)),\n",
    "    \"BiLSTM\": build_bilstm_model((num_features, 1)),\n",
    "    \"CNN_LSTM\": build_cnn_lstm_model((num_features, 1)),\n",
    "    \"Transformer\": build_transformer_model((num_features, 1)),\n",
    "    \"TCN\": build_tcn_model((num_features, 1)),\n",
    "    \"Autoencoder\": build_supervised_autoencoder(X_train_scaled.shape[1])\n",
    "}\n",
    "\n",
    "results = {}\n",
    "epochs = 20\n",
    "batch_size = 32\n",
    "\n",
    "for model_name, model in models.items():\n",
    "    print(f\"\\n=== Training {model_name} Model ===\")\n",
    "    if model_name == \"Autoencoder\":\n",
    "        # Train the autoencoder model on flat input.\n",
    "        history = model.fit(X_train_scaled, {\"reconstruction\": X_train_scaled, \"classifier\": y_train},\n",
    "                            epochs=epochs, batch_size=batch_size, validation_split=0.1, verbose=1)\n",
    "        # Evaluate on the test set.\n",
    "        eval_results = model.evaluate(X_test_scaled, {\"reconstruction\": X_test_scaled, \"classifier\": y_test}, verbose=0)\n",
    "        # The classifier branch is the second output.\n",
    "        y_pred_probs = model.predict(X_test_scaled)[1]\n",
    "    else:\n",
    "        # Train sequence-based models on reshaped data.\n",
    "        history = model.fit(X_train_seq, y_train, epochs=epochs, batch_size=batch_size,\n",
    "                            validation_split=0.1, verbose=1)\n",
    "        loss, acc = model.evaluate(X_test_seq, y_test, verbose=0)\n",
    "        y_pred_probs = model.predict(X_test_seq)\n",
    "    \n",
    "    y_pred = np.argmax(y_pred_probs, axis=1)\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    report = classification_report(y_test, y_pred)\n",
    "    \n",
    "    # For autoencoder, extract classifier accuracy from evaluation metrics if needed.\n",
    "    if model_name == \"Autoencoder\":\n",
    "        # The evaluation returned [total_loss, rec_loss, classifier_loss, classifier_accuracy]\n",
    "        clf_acc = eval_results[-1]\n",
    "        print(f\"{model_name} - Test Classifier Accuracy: {clf_acc:.4f}\")\n",
    "    else:\n",
    "        print(f\"{model_name} - Test Accuracy: {acc:.4f}\")\n",
    "    \n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(cm)\n",
    "    print(\"Classification Report:\")\n",
    "    print(report)\n",
    "    \n",
    "    results[model_name] = {\n",
    "        \"accuracy\": clf_acc if model_name == \"Autoencoder\" else acc,\n",
    "        \"confusion_matrix\": cm,\n",
    "        \"classification_report\": report\n",
    "    }\n",
    "\n",
    "# ===== 4. Compare Overall Model Performance =====\n",
    "print(\"\\n=== Overall Model Performance ===\")\n",
    "for model_name, metrics in results.items():\n",
    "    print(f\"{model_name}: Accuracy = {metrics['accuracy']:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2104c3a2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5175e9a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6918ae31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "print(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d660d4a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ef3c1d26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Categorical columns: ['Gender', 'self_employed', 'family_history', 'treatment', 'Days_Indoors', 'Growing_Stress', 'Changes_Habits', 'Mental_Health_History', 'Mood_Swings', 'Coping_Struggles', 'Work_Interest', 'Social_Weakness', 'mental_health_interview', 'care_options']\n",
      "\n",
      "=== Training LSTM Model ===\n",
      "Epoch 1/10\n",
      "6579/6579 [==============================] - 15s 2ms/step - loss: 1.0737 - accuracy: 0.3926 - val_loss: 1.0150 - val_accuracy: 0.4616\n",
      "Epoch 2/10\n",
      "6579/6579 [==============================] - 14s 2ms/step - loss: 0.7618 - accuracy: 0.6175 - val_loss: 0.3691 - val_accuracy: 0.8294\n",
      "Epoch 3/10\n",
      "6579/6579 [==============================] - 14s 2ms/step - loss: 0.3414 - accuracy: 0.8341 - val_loss: 0.2388 - val_accuracy: 0.8770\n",
      "Epoch 4/10\n",
      "6579/6579 [==============================] - 14s 2ms/step - loss: 0.2488 - accuracy: 0.8766 - val_loss: 0.1803 - val_accuracy: 0.9067\n",
      "Epoch 5/10\n",
      "6579/6579 [==============================] - 15s 2ms/step - loss: 0.1809 - accuracy: 0.9100 - val_loss: 0.1163 - val_accuracy: 0.9338\n",
      "Epoch 6/10\n",
      "6579/6579 [==============================] - 15s 2ms/step - loss: 0.1415 - accuracy: 0.9276 - val_loss: 0.0974 - val_accuracy: 0.9422\n",
      "Epoch 7/10\n",
      "6579/6579 [==============================] - 17s 3ms/step - loss: 0.1208 - accuracy: 0.9356 - val_loss: 0.0876 - val_accuracy: 0.9440\n",
      "Epoch 8/10\n",
      "6579/6579 [==============================] - 17s 3ms/step - loss: 0.1124 - accuracy: 0.9386 - val_loss: 0.1121 - val_accuracy: 0.9369\n",
      "Epoch 9/10\n",
      "6579/6579 [==============================] - 15s 2ms/step - loss: 0.1045 - accuracy: 0.9407 - val_loss: 0.0807 - val_accuracy: 0.9455\n",
      "Epoch 10/10\n",
      "6579/6579 [==============================] - 16s 2ms/step - loss: 0.1009 - accuracy: 0.9420 - val_loss: 0.0802 - val_accuracy: 0.9458\n",
      "1828/1828 [==============================] - 2s 750us/step\n",
      "LSTM - Test Loss: 0.0787, Test Accuracy: 0.9481\n",
      "Confusion Matrix:\n",
      "[[17153   553   406]\n",
      " [  130 19796   194]\n",
      " [  687  1062 18492]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.95      0.95     18112\n",
      "           1       0.92      0.98      0.95     20120\n",
      "           2       0.97      0.91      0.94     20241\n",
      "\n",
      "    accuracy                           0.95     58473\n",
      "   macro avg       0.95      0.95      0.95     58473\n",
      "weighted avg       0.95      0.95      0.95     58473\n",
      "\n",
      "\n",
      "=== Overall Model Performance ===\n",
      "LSTM: Accuracy = 0.9481\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization, Conv1D, GlobalMaxPooling1D, LSTM\n",
    "\n",
    "# === 1. Data Preprocessing ===\n",
    "\n",
    "# Load the dataset\n",
    "file_path = \"Mental Health Dataset.csv\"\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Drop irrelevant columns (adjust as needed)\n",
    "df = df.drop(columns=['Timestamp', 'Country', 'Occupation'])\n",
    "\n",
    "# Fill missing values using the mode for each column\n",
    "df = df.fillna(df.mode().iloc[0])\n",
    "\n",
    "# Identify all categorical columns\n",
    "categorical_cols = df.select_dtypes(include=['object']).columns.tolist()\n",
    "print(\"Categorical columns:\", categorical_cols)\n",
    "\n",
    "# Encode all categorical columns using LabelEncoder\n",
    "label_encoders = {}\n",
    "for col in categorical_cols:\n",
    "    le = LabelEncoder()\n",
    "    df[col] = le.fit_transform(df[col])\n",
    "    label_encoders[col] = le\n",
    "\n",
    "# Separate features and target (target is \"Mood_Swings\")\n",
    "X = df.drop(columns=['Mood_Swings'])\n",
    "y = df['Mood_Swings']\n",
    "\n",
    "# Split the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Standardize the features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# For CNN and LSTM models, reshape data as a sequence (each feature as a \"time step\")\n",
    "num_features = X_train_scaled.shape[1]\n",
    "X_train_seq = X_train_scaled.reshape(-1, num_features, 1)\n",
    "X_test_seq = X_test_scaled.reshape(-1, num_features, 1)\n",
    "\n",
    "# Determine the number of classes for output layer\n",
    "num_classes = len(np.unique(y))\n",
    "\n",
    "# === 2. Define Deep Learning Models ===\n",
    "\n",
    "\n",
    "# Model 4: LSTM Model (treat features as a sequence)\n",
    "def build_lstm_model(input_shape):\n",
    "    model = Sequential([\n",
    "        LSTM(64, input_shape=input_shape),\n",
    "        Dropout(0.3),\n",
    "        Dense(64, activation='relu'),\n",
    "        Dropout(0.2),\n",
    "        Dense(num_classes, activation='softmax')\n",
    "    ])\n",
    "    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# === 3. Train and Evaluate Models ===\n",
    "\n",
    "models = {\n",
    "    \"LSTM\": build_lstm_model((num_features, 1))\n",
    "}\n",
    "\n",
    "results = {}\n",
    "\n",
    "for model_name, model in models.items():\n",
    "    print(f\"\\n=== Training {model_name} Model ===\")\n",
    "    \n",
    "    if model_name in [\"CNN\", \"LSTM\"]:\n",
    "        history = model.fit(X_train_seq, y_train, epochs=10, batch_size=32,\n",
    "                            validation_split=0.1, verbose=1)\n",
    "        loss, acc = model.evaluate(X_test_seq, y_test, verbose=0)\n",
    "        y_pred_probs = model.predict(X_test_seq)\n",
    "    else:\n",
    "        history = model.fit(X_train_scaled, y_train, epochs=10, batch_size=32,\n",
    "                            validation_split=0.1, verbose=1)\n",
    "        loss, acc = model.evaluate(X_test_scaled, y_test, verbose=0)\n",
    "        y_pred_probs = model.predict(X_test_scaled)\n",
    "    \n",
    "    # Convert predicted probabilities to class labels\n",
    "    y_pred = np.argmax(y_pred_probs, axis=1)\n",
    "    \n",
    "    # Generate confusion matrix and classification report\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    report = classification_report(y_test, y_pred)\n",
    "    \n",
    "    print(f\"{model_name} - Test Loss: {loss:.4f}, Test Accuracy: {acc:.4f}\")\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(cm)\n",
    "    print(\"Classification Report:\")\n",
    "    print(report)\n",
    "    \n",
    "    results[model_name] = {\n",
    "        \"loss\": loss,\n",
    "        \"accuracy\": acc,\n",
    "        \"confusion_matrix\": cm,\n",
    "        \"classification_report\": report\n",
    "    }\n",
    "\n",
    "# === 4. Model Performance Comparison ===\n",
    "\n",
    "print(\"\\n=== Overall Model Performance ===\")\n",
    "for model_name, metrics in results.items():\n",
    "    print(f\"{model_name}: Accuracy = {metrics['accuracy']:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28ea12cc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02eaed1e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "915f3138",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "934970dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LSTM model saved as lstm_model.h5\n",
      "Scaler saved as scaler.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/vamsipusapati/anaconda3/lib/python3.11/site-packages/keras/src/engine/training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "lstm_model = models.get(\"LSTM\")\n",
    "# Save the LSTM model to an H5 file\n",
    "lstm_model.save('lstm_model.h5')\n",
    "print(\"LSTM model saved as lstm_model.h5\")\n",
    "\n",
    "# Save the scaler object using pickle\n",
    "with open('scaler.pkl', 'wb') as file:\n",
    "    pickle.dump(scaler, file)\n",
    "print(\"Scaler saved as scaler.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c6cb0cc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LSTM model loaded successfully.\n",
      "Scaler loaded successfully.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "import pickle\n",
    "\n",
    "# Load the saved LSTM model\n",
    "lstm_model = load_model('lstm_model.h5')\n",
    "print(\"LSTM model loaded successfully.\")\n",
    "\n",
    "# Load the scaler object\n",
    "with open('scaler.pkl', 'rb') as file:\n",
    "    scaler = pickle.load(file)\n",
    "print(\"Scaler loaded successfully.\")\n",
    "# Load the Label object\n",
    "with open('label_encoders.pkl', 'wb') as f:\n",
    "    pickle.dump(label_encoders, f)\n",
    "    \n",
    "print(\"Label loaded successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "02cc3587",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label loaded successfully.\n"
     ]
    }
   ],
   "source": [
    "with open('label_encoders.pkl', 'wb') as f:\n",
    "    pickle.dump(label_encoders, f)\n",
    "    \n",
    "print(\"Label loaded successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "433fe05c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LSTM model loaded.\n",
      "Scaler loaded.\n",
      "Label encoders loaded.\n",
      "\n",
      "Please answer the following questions by entering the option number:\n",
      "\n",
      "Gender:\n",
      "  1. Female\n",
      "  2. Male\n",
      "Enter the option number: 1\n",
      "\n",
      "self_employed:\n",
      "  1. No\n",
      "  2. Yes\n",
      "Enter the option number: 2\n",
      "\n",
      "family_history:\n",
      "  1. No\n",
      "  2. Yes\n",
      "Enter the option number: 1\n",
      "\n",
      "treatment:\n",
      "  1. No\n",
      "  2. Yes\n",
      "Enter the option number: 1\n",
      "\n",
      "Days_Indoors:\n",
      "  1. Go out Every day\n",
      "  2. 1-14 days\n",
      "  3. 15-30 days\n",
      "  4. 31-60 days\n",
      "  5. More than 2 months\n",
      "Enter the option number: 5\n",
      "\n",
      "Growing_Stress:\n",
      "  1. Maybe\n",
      "  2. No\n",
      "  3. Yes\n",
      "Enter the option number: 1\n",
      "\n",
      "Changes_Habits:\n",
      "  1. Maybe\n",
      "  2. No\n",
      "  3. Yes\n",
      "Enter the option number: 2\n",
      "\n",
      "Mental_Health_History:\n",
      "  1. Maybe\n",
      "  2. No\n",
      "  3. Yes\n",
      "Enter the option number: 3\n",
      "\n",
      "Coping_Struggles:\n",
      "  1. No\n",
      "  2. Yes\n",
      "Enter the option number: 2\n",
      "\n",
      "Work_Interest:\n",
      "  1. Maybe\n",
      "  2. No\n",
      "  3. Yes\n",
      "Enter the option number: 1\n",
      "\n",
      "Social_Weakness:\n",
      "  1. Maybe\n",
      "  2. No\n",
      "  3. Yes\n",
      "Enter the option number: 1\n",
      "\n",
      "mental_health_interview:\n",
      "  1. Maybe\n",
      "  2. No\n",
      "  3. Yes\n",
      "Enter the option number: 1\n",
      "\n",
      "care_options:\n",
      "  1. No\n",
      "  2. Not sure\n",
      "  3. Yes\n",
      "Enter the option number: 2\n",
      "\n",
      "User input received:\n",
      "   Gender self_employed family_history treatment        Days_Indoors  \\\n",
      "0  Female           Yes             No        No  More than 2 months   \n",
      "\n",
      "  Growing_Stress Changes_Habits Mental_Health_History Coping_Struggles  \\\n",
      "0          Maybe             No                   Yes              Yes   \n",
      "\n",
      "  Work_Interest Social_Weakness mental_health_interview care_options  \n",
      "0         Maybe           Maybe                   Maybe     Not sure  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/vamsipusapati/anaconda3/lib/python3.11/site-packages/sklearn/base.py:464: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 184ms/step\n",
      "\n",
      "Predicted Stress (Mood Swing) Class: 1\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# === 1. Load Saved Artifacts ===\n",
    "lstm_model = load_model('lstm_model.h5')\n",
    "print(\"LSTM model loaded.\")\n",
    "\n",
    "with open('scaler.pkl', 'rb') as f:\n",
    "    scaler = pickle.load(f)\n",
    "print(\"Scaler loaded.\")\n",
    "\n",
    "with open('label_encoders.pkl', 'rb') as f:\n",
    "    label_encoders = pickle.load(f)\n",
    "print(\"Label encoders loaded.\")\n",
    "\n",
    "# === 2. Define Questions and Options Based on the CSV Columns ===\n",
    "# These options are inferred from the sample dataset.\n",
    "questions_options = {\n",
    "    \"Gender\": [\"Female\", \"Male\"],\n",
    "    \"self_employed\": [\"No\", \"Yes\"],\n",
    "    \"family_history\": [\"No\", \"Yes\"],\n",
    "    \"treatment\": [\"No\", \"Yes\"],\n",
    "    \"Days_Indoors\": [\"Go out Every day\", \"1-14 days\", \"15-30 days\", \"31-60 days\", \"More than 2 months\"],\n",
    "    \"Growing_Stress\": [\"Maybe\", \"No\", \"Yes\"],\n",
    "    \"Changes_Habits\": [\"Maybe\", \"No\", \"Yes\"],\n",
    "    \"Mental_Health_History\": [\"Maybe\", \"No\", \"Yes\"],\n",
    "    \"Coping_Struggles\": [\"No\", \"Yes\"],\n",
    "    \"Work_Interest\": [\"Maybe\", \"No\", \"Yes\"],\n",
    "    \"Social_Weakness\": [\"Maybe\", \"No\", \"Yes\"],\n",
    "    \"mental_health_interview\": [\"Maybe\", \"No\", \"Yes\"],\n",
    "    \"care_options\": [\"No\", \"Not sure\", \"Yes\"]\n",
    "}\n",
    "\n",
    "# === 3. Collect User Input via the Chatbot Interface ===\n",
    "user_data = {}\n",
    "print(\"\\nPlease answer the following questions by entering the option number:\")\n",
    "\n",
    "for feature, options in questions_options.items():\n",
    "    print(f\"\\n{feature}:\")\n",
    "    for idx, option in enumerate(options, start=1):\n",
    "        print(f\"  {idx}. {option}\")\n",
    "    while True:\n",
    "        choice = input(\"Enter the option number: \")\n",
    "        try:\n",
    "            choice_index = int(choice) - 1\n",
    "            if 0 <= choice_index < len(options):\n",
    "                user_data[feature] = options[choice_index]\n",
    "                break\n",
    "            else:\n",
    "                print(\"Invalid choice. Please try again.\")\n",
    "        except ValueError:\n",
    "            print(\"Invalid input. Please enter a number.\")\n",
    "\n",
    "# Display the collected inputs\n",
    "df_input = pd.DataFrame([user_data])\n",
    "print(\"\\nUser input received:\")\n",
    "print(df_input)\n",
    "\n",
    "# === 4. Encode the User Input Using the Saved Label Encoders ===\n",
    "# Each feature should be encoded using the same encoder as used during training.\n",
    "for feature in questions_options.keys():\n",
    "    if feature in label_encoders:\n",
    "        le = label_encoders[feature]\n",
    "        try:\n",
    "            df_input[feature] = le.transform(df_input[feature])\n",
    "        except Exception as e:\n",
    "            print(f\"Error encoding {feature}: {e}\")\n",
    "            exit(1)\n",
    "    else:\n",
    "        # If any feature is numeric, ensure proper conversion\n",
    "        df_input[feature] = pd.to_numeric(df_input[feature], errors='coerce')\n",
    "\n",
    "# Arrange features in the same order as used in training\n",
    "features_order = list(questions_options.keys())\n",
    "X_input = df_input[features_order].values\n",
    "\n",
    "# === 5. Preprocess the Input and Predict Using the LSTM Model ===\n",
    "# Scale the input using the saved scaler\n",
    "X_input_scaled = scaler.transform(X_input)\n",
    "\n",
    "# Reshape input to 3D as expected by the LSTM: (samples, timesteps, channels)\n",
    "num_features = X_input_scaled.shape[1]\n",
    "X_input_seq = X_input_scaled.reshape(-1, num_features, 1)\n",
    "\n",
    "# Get prediction probabilities and predicted class\n",
    "prediction_probabilities = lstm_model.predict(X_input_seq)\n",
    "predicted_class = np.argmax(prediction_probabilities, axis=1)\n",
    "\n",
    "print(\"\\nPredicted Stress (Mood Swing) Class:\", predicted_class[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "aad1048b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Categorical columns: ['Gender', 'self_employed', 'family_history', 'treatment', 'Days_Indoors', 'Growing_Stress', 'Changes_Habits', 'Mental_Health_History', 'Mood_Swings', 'Coping_Struggles', 'Work_Interest', 'Social_Weakness', 'mental_health_interview', 'care_options']\n"
     ]
    }
   ],
   "source": [
    "# === 1. Data Preprocessing ===\n",
    "\n",
    "# Load the dataset\n",
    "file_path = \"Mental Health Dataset.csv\"\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Drop irrelevant columns (adjust as needed)\n",
    "df = df.drop(columns=['Timestamp', 'Country', 'Occupation'])\n",
    "\n",
    "# Fill missing values using the mode for each column\n",
    "df = df.fillna(df.mode().iloc[0])\n",
    "\n",
    "# Identify all categorical columns\n",
    "categorical_cols = df.select_dtypes(include=['object']).columns.tolist()\n",
    "print(\"Categorical columns:\", categorical_cols)\n",
    "\n",
    "# Encode all categorical columns using LabelEncoder\n",
    "label_encoders = {}\n",
    "for col in categorical_cols:\n",
    "    le = LabelEncoder()\n",
    "    df[col] = le.fit_transform(df[col])\n",
    "    label_encoders[col] = le\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "15a6ba5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = label_encoders['Days_Indoors']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f6ef5557",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gender\n",
      "{'classes_': array(['Female', 'Male'], dtype=object)}\n",
      "self_employed\n",
      "{'classes_': array(['No', 'Yes'], dtype=object)}\n",
      "family_history\n",
      "{'classes_': array(['No', 'Yes'], dtype=object)}\n",
      "treatment\n",
      "{'classes_': array(['No', 'Yes'], dtype=object)}\n",
      "Days_Indoors\n",
      "{'classes_': array(['1-14 days', '15-30 days', '31-60 days', 'Go out Every day',\n",
      "       'More than 2 months'], dtype=object)}\n",
      "Growing_Stress\n",
      "{'classes_': array(['Maybe', 'No', 'Yes'], dtype=object)}\n",
      "Changes_Habits\n",
      "{'classes_': array(['Maybe', 'No', 'Yes'], dtype=object)}\n",
      "Mental_Health_History\n",
      "{'classes_': array(['Maybe', 'No', 'Yes'], dtype=object)}\n",
      "Mood_Swings\n",
      "{'classes_': array(['High', 'Low', 'Medium'], dtype=object)}\n",
      "Coping_Struggles\n",
      "{'classes_': array(['No', 'Yes'], dtype=object)}\n",
      "Work_Interest\n",
      "{'classes_': array(['Maybe', 'No', 'Yes'], dtype=object)}\n",
      "Social_Weakness\n",
      "{'classes_': array(['Maybe', 'No', 'Yes'], dtype=object)}\n",
      "mental_health_interview\n",
      "{'classes_': array(['Maybe', 'No', 'Yes'], dtype=object)}\n",
      "care_options\n",
      "{'classes_': array(['No', 'Not sure', 'Yes'], dtype=object)}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for a in label_encoders:\n",
    "    print(a)\n",
    "    print(label_encoders[a].__dict__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "579bc017",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Gender': LabelEncoder(),\n",
       " 'self_employed': LabelEncoder(),\n",
       " 'family_history': LabelEncoder(),\n",
       " 'treatment': LabelEncoder(),\n",
       " 'Days_Indoors': LabelEncoder(),\n",
       " 'Growing_Stress': LabelEncoder(),\n",
       " 'Changes_Habits': LabelEncoder(),\n",
       " 'Mental_Health_History': LabelEncoder(),\n",
       " 'Mood_Swings': LabelEncoder(),\n",
       " 'Coping_Struggles': LabelEncoder(),\n",
       " 'Work_Interest': LabelEncoder(),\n",
       " 'Social_Weakness': LabelEncoder(),\n",
       " 'mental_health_interview': LabelEncoder(),\n",
       " 'care_options': LabelEncoder()}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "questions_options = {\n",
    "    \"Gender\": [\"Female\", \"Male\"],\n",
    "    \"self_employed\": [\"No\", \"Yes\"],\n",
    "    \"family_history\": [\"No\", \"Yes\"],\n",
    "    \"treatment\": [\"No\", \"Yes\"],\n",
    "    \"Days_Indoors\": [\"Go out Every day\", \"1-14 days\", \"15-30 days\", \"31-60 days\", \"More than 2 months\"],\n",
    "    \"Growing_Stress\": [\"Maybe\", \"No\", \"Yes\"],\n",
    "    \"Changes_Habits\": [\"Maybe\", \"No\", \"Yes\"],\n",
    "    \"Mental_Health_History\": [\"Maybe\", \"No\", \"Yes\"],\n",
    "    \"Coping_Struggles\": [\"No\", \"Yes\"],\n",
    "    \"Work_Interest\": [\"Maybe\", \"No\", \"Yes\"],\n",
    "    \"Social_Weakness\": [\"Maybe\", \"No\", \"Yes\"],\n",
    "    \"mental_health_interview\": [\"Maybe\", \"No\", \"Yes\"],\n",
    "    \"care_options\": [\"No\", \"Not sure\", \"Yes\"]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a364e893",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Package                       Version\r\n",
      "----------------------------- ---------\r\n",
      "absl-py                       2.0.0\r\n",
      "aiobotocore                   2.5.0\r\n",
      "aiofiles                      22.1.0\r\n",
      "aiogrpc                       1.8\r\n",
      "aiohttp                       3.9.3\r\n",
      "aiohttp-retry                 2.8.3\r\n",
      "aioitertools                  0.7.1\r\n",
      "aiosignal                     1.2.0\r\n",
      "aiosqlite                     0.18.0\r\n",
      "alabaster                     0.7.12\r\n",
      "anaconda-catalogs             0.2.0\r\n",
      "anaconda-client               1.12.0\r\n",
      "anaconda-navigator            2.4.2\r\n",
      "anaconda-project              0.11.1\r\n",
      "annotated-types               0.6.0\r\n",
      "anyio                         3.5.0\r\n",
      "appdirs                       1.4.4\r\n",
      "applaunchservices             0.3.0\r\n",
      "appnope                       0.1.2\r\n",
      "appscript                     1.1.2\r\n",
      "APScheduler                   3.10.4\r\n",
      "argon2-cffi                   21.3.0\r\n",
      "argon2-cffi-bindings          21.2.0\r\n",
      "arrow                         1.2.3\r\n",
      "astroid                       2.14.2\r\n",
      "astropy                       5.1\r\n",
      "asttokens                     2.0.5\r\n",
      "astunparse                    1.6.3\r\n",
      "async-timeout                 4.0.2\r\n",
      "atomicwrites                  1.4.0\r\n",
      "attrs                         22.1.0\r\n",
      "Automat                       20.2.0\r\n",
      "autopep8                      1.6.0\r\n",
      "Babel                         2.11.0\r\n",
      "backcall                      0.2.0\r\n",
      "backports.functools-lru-cache 1.6.4\r\n",
      "backports.tempfile            1.0\r\n",
      "backports.weakref             1.0.post1\r\n",
      "bcrypt                        3.2.0\r\n",
      "beautifulsoup4                4.12.2\r\n",
      "bidict                        0.22.1\r\n",
      "binaryornot                   0.4.4\r\n",
      "biotite                       0.40.0\r\n",
      "black                         0.0\r\n",
      "bleach                        4.1.0\r\n",
      "blinker                       1.7.0\r\n",
      "bokeh                         3.2.1\r\n",
      "boltons                       23.0.0\r\n",
      "botocore                      1.29.76\r\n",
      "Bottleneck                    1.3.5\r\n",
      "brotlipy                      0.7.0\r\n",
      "cachelib                      0.10.2\r\n",
      "cachetools                    5.3.2\r\n",
      "certifi                       2023.7.22\r\n",
      "cffi                          1.15.1\r\n",
      "chardet                       4.0.0\r\n",
      "charset-normalizer            2.0.4\r\n",
      "click                         8.1.7\r\n",
      "cloudpickle                   2.2.1\r\n",
      "clyent                        1.2.2\r\n",
      "colorama                      0.4.6\r\n",
      "colorcet                      3.0.1\r\n",
      "comm                          0.1.2\r\n",
      "conda                         23.7.2\r\n",
      "conda-build                   3.26.0\r\n",
      "conda-content-trust           0+unknown\r\n",
      "conda_index                   0.2.3\r\n",
      "conda-libmamba-solver         23.5.0\r\n",
      "conda-pack                    0.6.0\r\n",
      "conda-package-handling        2.2.0\r\n",
      "conda_package_streaming       0.9.0\r\n",
      "conda-repo-cli                1.0.41\r\n",
      "conda-token                   0.4.0\r\n",
      "conda-verify                  3.4.2\r\n",
      "constantly                    15.1.0\r\n",
      "contourpy                     1.0.5\r\n",
      "cookiecutter                  1.7.3\r\n",
      "cryptography                  41.0.2\r\n",
      "cssselect                     1.1.0\r\n",
      "cycler                        0.11.0\r\n",
      "cytoolz                       0.12.0\r\n",
      "dask                          2023.6.0\r\n",
      "dataclasses-json              0.6.7\r\n",
      "datasets                      2.12.0\r\n",
      "datashader                    0.15.1\r\n",
      "datashape                     0.5.4\r\n",
      "debugpy                       1.6.7\r\n",
      "decorator                     5.1.1\r\n",
      "defusedxml                    0.7.1\r\n",
      "detoxify                      0.5.2\r\n",
      "dgl                           2.1.0\r\n",
      "diff-match-patch              20200713\r\n",
      "dill                          0.3.6\r\n",
      "distributed                   2023.6.0\r\n",
      "distro                        1.9.0\r\n",
      "dnspython                     2.5.0\r\n",
      "docstring-to-markdown         0.11\r\n",
      "docutils                      0.18.1\r\n",
      "entrypoints                   0.4\r\n",
      "et-xmlfile                    1.1.0\r\n",
      "executing                     0.8.3\r\n",
      "fair-esm                      2.0.1\r\n",
      "fastjsonschema                2.16.2\r\n",
      "filelock                      3.9.0\r\n",
      "findspark                     2.0.1\r\n",
      "flake8                        6.0.0\r\n",
      "Flask                         3.0.1\r\n",
      "Flask-Bcrypt                  1.0.1\r\n",
      "Flask-Cors                    4.0.0\r\n",
      "Flask-Session                 0.6.0\r\n",
      "Flask-Sessions                0.1.5\r\n",
      "Flask-SocketIO                5.3.6\r\n",
      "Flask-SQLAlchemy              3.1.1\r\n",
      "flatbuffers                   23.5.26\r\n",
      "fonttools                     4.25.0\r\n",
      "frozenlist                    1.3.3\r\n",
      "fsspec                        2023.4.0\r\n",
      "future                        0.18.3\r\n",
      "gast                          0.5.4\r\n",
      "gensim                        4.3.0\r\n",
      "glob2                         0.7\r\n",
      "gmpy2                         2.1.2\r\n",
      "gnureadline                   8.1.2\r\n",
      "google-auth                   2.23.4\r\n",
      "google-auth-oauthlib          1.0.0\r\n",
      "google-pasta                  0.2.0\r\n",
      "greenlet                      2.0.1\r\n",
      "grpcio                        1.59.2\r\n",
      "gurobipy                      11.0.0\r\n",
      "h11                           0.14.0\r\n",
      "h5py                          3.7.0\r\n",
      "HeapDict                      1.0.1\r\n",
      "holoviews                     1.17.0\r\n",
      "httpcore                      1.0.5\r\n",
      "httpx                         0.27.0\r\n",
      "huggingface-hub               0.15.1\r\n",
      "hvplot                        0.8.4\r\n",
      "hyperlink                     21.0.0\r\n",
      "idna                          3.4\r\n",
      "imagecodecs                   2021.8.26\r\n",
      "imageio                       2.31.1\r\n",
      "imagesize                     1.4.1\r\n",
      "imbalanced-learn              0.10.1\r\n",
      "importlib-metadata            6.0.0\r\n",
      "incremental                   21.3.0\r\n",
      "inflection                    0.5.1\r\n",
      "iniconfig                     1.1.1\r\n",
      "intake                        0.6.8\r\n",
      "interchange                   2021.0.4\r\n",
      "intervaltree                  3.1.0\r\n",
      "ipykernel                     6.19.2\r\n",
      "ipython                       8.12.0\r\n",
      "ipython-genutils              0.2.0\r\n",
      "ipywidgets                    8.0.4\r\n",
      "isodate                       0.6.1\r\n",
      "isort                         5.9.3\r\n",
      "itemadapter                   0.3.0\r\n",
      "itemloaders                   1.0.4\r\n",
      "itsdangerous                  2.1.2\r\n",
      "jaraco.classes                3.2.1\r\n",
      "jedi                          0.18.1\r\n",
      "jellyfish                     0.9.0\r\n",
      "Jinja2                        3.1.2\r\n",
      "jinja2-time                   0.2.0\r\n",
      "jmespath                      0.10.0\r\n",
      "joblib                        1.2.0\r\n",
      "json5                         0.9.6\r\n",
      "jsonpatch                     1.33\r\n",
      "jsonpointer                   2.1\r\n",
      "jsonschema                    4.17.3\r\n",
      "jupyter                       1.0.0\r\n",
      "jupyter_client                7.4.9\r\n",
      "jupyter-console               6.6.3\r\n",
      "jupyter_core                  5.3.0\r\n",
      "jupyter-events                0.6.3\r\n",
      "jupyter-server                1.23.4\r\n",
      "jupyter_server_fileid         0.9.0\r\n",
      "jupyter_server_ydoc           0.8.0\r\n",
      "jupyter-ydoc                  0.2.4\r\n",
      "jupyterlab                    3.6.3\r\n",
      "jupyterlab-pygments           0.1.2\r\n",
      "jupyterlab_server             2.22.0\r\n",
      "jupyterlab-widgets            3.0.5\r\n",
      "kaleido                       0.2.1\r\n",
      "keras                         2.14.0\r\n",
      "keras-tcn                     3.5.4\r\n",
      "keyring                       23.13.1\r\n",
      "kiwisolver                    1.4.4\r\n",
      "langchain                     0.2.9\r\n",
      "langchain-community           0.2.7\r\n",
      "langchain-core                0.2.21\r\n",
      "langchain-openai              0.1.17\r\n",
      "langchain-text-splitters      0.2.2\r\n",
      "langsmith                     0.1.92\r\n",
      "lazy_loader                   0.2\r\n",
      "lazy-object-proxy             1.6.0\r\n",
      "libarchive-c                  2.9\r\n",
      "libclang                      16.0.6\r\n",
      "libmambapy                    1.4.1\r\n",
      "linkify-it-py                 2.0.0\r\n",
      "llvmlite                      0.40.0\r\n",
      "lmdb                          1.4.1\r\n",
      "locket                        1.0.0\r\n",
      "lxml                          4.9.2\r\n",
      "lz4                           4.3.2\r\n",
      "Markdown                      3.4.1\r\n",
      "markdown-it-py                2.2.0\r\n",
      "MarkupSafe                    2.1.1\r\n",
      "marshmallow                   3.21.3\r\n",
      "matplotlib                    3.7.1\r\n",
      "matplotlib-inline             0.1.6\r\n",
      "mavsdk                        2.8.4\r\n",
      "mccabe                        0.7.0\r\n",
      "mdit-py-plugins               0.3.0\r\n",
      "mdurl                         0.1.0\r\n",
      "mistune                       0.8.4\r\n",
      "ml-dtypes                     0.2.0\r\n",
      "monotonic                     1.6\r\n",
      "more-itertools                8.12.0\r\n",
      "mpmath                        1.3.0\r\n",
      "msgpack                       1.0.3\r\n",
      "multidict                     6.0.2\r\n",
      "multipledispatch              0.6.0\r\n",
      "multiprocess                  0.70.14\r\n",
      "munkres                       1.1.4\r\n",
      "mypy-extensions               0.4.3\r\n",
      "navigator-updater             0.4.0\r\n",
      "nbclassic                     0.5.5\r\n",
      "nbclient                      0.5.13\r\n",
      "nbconvert                     6.5.4\r\n",
      "nbformat                      5.7.0\r\n",
      "nbmerge                       0.0.4\r\n",
      "neo4j                         5.19.0\r\n",
      "nest-asyncio                  1.5.6\r\n",
      "networkx                      3.1\r\n",
      "nltk                          3.8.1\r\n",
      "notebook                      6.5.4\r\n",
      "notebook_shim                 0.2.2\r\n",
      "numba                         0.57.0\r\n",
      "numexpr                       2.8.4\r\n",
      "numpy                         1.24.3\r\n",
      "numpydoc                      1.5.0\r\n",
      "oauthlib                      3.2.2\r\n",
      "openai                        1.35.15\r\n",
      "openpyxl                      3.0.10\r\n",
      "opt-einsum                    3.3.0\r\n",
      "orjson                        3.10.6\r\n",
      "packaging                     24.1\r\n",
      "pandas                        1.5.3\r\n",
      "pandocfilters                 1.5.0\r\n",
      "panel                         1.2.1\r\n",
      "pansi                         2020.7.3\r\n",
      "param                         1.13.0\r\n",
      "parsel                        1.6.0\r\n",
      "parso                         0.8.3\r\n",
      "partd                         1.2.0\r\n",
      "pathlib                       1.0.1\r\n",
      "pathspec                      0.10.3\r\n",
      "patsy                         0.5.3\r\n",
      "pep8                          1.7.1\r\n",
      "pexpect                       4.8.0\r\n",
      "pickleshare                   0.7.5\r\n",
      "Pillow                        9.4.0\r\n",
      "pip                           23.2.1\r\n",
      "pkginfo                       1.9.6\r\n",
      "platformdirs                  2.5.2\r\n",
      "plotly                        5.9.0\r\n",
      "pluggy                        1.0.0\r\n",
      "ply                           3.11\r\n",
      "pooch                         1.4.0\r\n",
      "poyo                          0.5.0\r\n",
      "prometheus-client             0.14.1\r\n",
      "prompt-toolkit                3.0.36\r\n",
      "Protego                       0.1.16\r\n",
      "protobuf                      4.25.6\r\n",
      "psutil                        5.9.0\r\n",
      "ptyprocess                    0.7.0\r\n",
      "pure-eval                     0.2.2\r\n",
      "py-cpuinfo                    8.0.0\r\n",
      "py2neo                        2021.2.4\r\n",
      "py3Dmol                       2.1.0\r\n",
      "py4j                          0.10.9.7\r\n",
      "pyarrow                       11.0.0\r\n",
      "pyasn1                        0.4.8\r\n",
      "pyasn1-modules                0.2.8\r\n",
      "pycodestyle                   2.10.0\r\n",
      "pycosat                       0.6.4\r\n",
      "pycparser                     2.21\r\n",
      "pyct                          0.5.0\r\n",
      "pycurl                        7.45.2\r\n",
      "pydantic                      2.7.0\r\n",
      "pydantic_core                 2.18.1\r\n",
      "PyDispatcher                  2.0.5\r\n",
      "pydocstyle                    6.3.0\r\n",
      "pyee                          8.2.2\r\n",
      "pyerfa                        2.0.0\r\n",
      "pyflakes                      3.0.1\r\n",
      "Pygments                      2.15.1\r\n",
      "PyJWT                         2.4.0\r\n",
      "pylint                        2.16.2\r\n",
      "pylint-venv                   2.3.0\r\n",
      "pyls-spyder                   0.4.0\r\n",
      "pymongo                       4.6.1\r\n",
      "PyMySQL                       1.1.0\r\n",
      "pyobjc-core                   9.0\r\n",
      "pyobjc-framework-Cocoa        9.0\r\n",
      "pyobjc-framework-CoreServices 9.0\r\n",
      "pyobjc-framework-FSEvents     9.0\r\n",
      "pyodbc                        4.0.34\r\n",
      "pyOpenSSL                     23.2.0\r\n",
      "pyparsing                     3.0.9\r\n",
      "pyppeteer                     1.0.2\r\n",
      "pyproject                     1.3.1\r\n",
      "pyproject-toml                0.0.10\r\n",
      "PyQt5-sip                     12.11.0\r\n",
      "pyrsistent                    0.18.0\r\n",
      "PySocks                       1.7.1\r\n",
      "pyspark                       3.5.1\r\n",
      "pytest                        7.4.0\r\n",
      "python-dateutil               2.8.2\r\n",
      "python-dotenv                 1.0.0\r\n",
      "python-engineio               4.8.2\r\n",
      "python-json-logger            2.0.7\r\n",
      "python-lsp-black              1.2.1\r\n",
      "python-lsp-jsonrpc            1.0.0\r\n",
      "python-lsp-server             1.7.2\r\n",
      "python-slugify                5.0.2\r\n",
      "python-snappy                 0.6.1\r\n",
      "python-socketio               5.11.0\r\n",
      "pytoolconfig                  1.2.5\r\n",
      "pytz                          2022.7\r\n",
      "pyviz-comms                   2.3.0\r\n",
      "PyWavelets                    1.4.1\r\n",
      "PyYAML                        6.0\r\n",
      "pyzmq                         23.2.0\r\n",
      "QDarkStyle                    3.0.2\r\n",
      "qstylizer                     0.2.2\r\n",
      "QtAwesome                     1.2.2\r\n",
      "qtconsole                     5.4.2\r\n",
      "QtPy                          2.2.0\r\n",
      "queuelib                      1.5.0\r\n",
      "rdflib                        7.0.0\r\n",
      "regex                         2022.7.9\r\n",
      "requests                      2.31.0\r\n",
      "requests-file                 1.5.1\r\n",
      "requests-oauthlib             1.3.1\r\n",
      "requests-toolbelt             1.0.0\r\n",
      "responses                     0.13.3\r\n",
      "rfc3339-validator             0.1.4\r\n",
      "rfc3986-validator             0.1.1\r\n",
      "rope                          1.7.0\r\n",
      "rsa                           4.9\r\n",
      "Rtree                         1.0.1\r\n",
      "ruamel.yaml                   0.17.21\r\n",
      "ruamel-yaml-conda             0.17.21\r\n",
      "s3fs                          2023.4.0\r\n",
      "sacremoses                    0.0.43\r\n",
      "scikit-image                  0.20.0\r\n",
      "scikit-learn                  1.3.0\r\n",
      "scipy                         1.10.1\r\n",
      "Scrapy                        2.8.0\r\n",
      "seaborn                       0.12.2\r\n",
      "Send2Trash                    1.8.0\r\n",
      "sentencepiece                 0.2.0\r\n",
      "service-identity              18.1.0\r\n",
      "setuptools                    68.0.0\r\n",
      "simple-websocket              1.0.0\r\n",
      "simpy                         4.1.1\r\n",
      "sip                           6.6.2\r\n",
      "six                           1.16.0\r\n",
      "smart-open                    5.2.1\r\n",
      "sniffio                       1.2.0\r\n",
      "snowballstemmer               2.2.0\r\n",
      "sortedcontainers              2.4.0\r\n",
      "soupsieve                     2.4\r\n",
      "spark-nlp                     5.3.3\r\n",
      "Sphinx                        5.0.2\r\n",
      "sphinxcontrib-applehelp       1.0.2\r\n",
      "sphinxcontrib-devhelp         1.0.2\r\n",
      "sphinxcontrib-htmlhelp        2.0.0\r\n",
      "sphinxcontrib-jsmath          1.0.1\r\n",
      "sphinxcontrib-qthelp          1.0.3\r\n",
      "sphinxcontrib-serializinghtml 1.1.5\r\n",
      "spyder                        5.4.3\r\n",
      "spyder-kernels                2.4.3\r\n",
      "SQLAlchemy                    2.0.25\r\n",
      "stack-data                    0.2.0\r\n",
      "statsmodels                   0.14.0\r\n",
      "style                         1.1.0\r\n",
      "sympy                         1.11.1\r\n",
      "tables                        3.8.0\r\n",
      "tabulate                      0.9.0\r\n",
      "TBB                           0.2\r\n",
      "tblib                         1.7.0\r\n",
      "tenacity                      8.2.2\r\n",
      "tensorboard                   2.14.1\r\n",
      "tensorboard-data-server       0.7.2\r\n",
      "tensorflow                    2.14.0\r\n",
      "tensorflow-addons             0.23.0\r\n",
      "tensorflow-estimator          2.14.0\r\n",
      "tensorflow-io-gcs-filesystem  0.34.0\r\n",
      "tensorflow-macos              2.14.0\r\n",
      "termcolor                     2.3.0\r\n",
      "terminado                     0.17.1\r\n",
      "text-unidecode                1.3\r\n",
      "textdistance                  4.2.1\r\n",
      "threadpoolctl                 2.2.0\r\n",
      "three-merge                   0.1.1\r\n",
      "tifffile                      2021.7.2\r\n",
      "tiktoken                      0.7.0\r\n",
      "tinycss2                      1.2.1\r\n",
      "tldextract                    3.2.0\r\n",
      "tokenizers                    0.13.2\r\n",
      "toml                          0.10.2\r\n",
      "tomlkit                       0.11.1\r\n",
      "toolz                         0.12.0\r\n",
      "torch                         2.1.1\r\n",
      "torch-cluster                 1.6.3\r\n",
      "torch_geometric               2.5.3\r\n",
      "torch-scatter                 2.1.2\r\n",
      "torch-sparse                  0.6.18\r\n",
      "torch-spline-conv             1.2.2\r\n",
      "torchaudio                    2.1.1\r\n",
      "torchdata                     0.7.1\r\n",
      "torchtext                     0.16.1\r\n",
      "torchvision                   0.16.1\r\n",
      "tornado                       6.3.2\r\n",
      "tqdm                          4.65.0\r\n",
      "traitlets                     5.7.1\r\n",
      "transformers                  4.29.2\r\n",
      "twilio                        8.13.0\r\n",
      "Twisted                       22.10.0\r\n",
      "typeguard                     2.13.3\r\n",
      "typing_extensions             4.7.1\r\n",
      "typing-inspect                0.9.0\r\n",
      "tzlocal                       5.2\r\n",
      "uc-micro-py                   1.0.1\r\n",
      "ujson                         5.4.0\r\n",
      "Unidecode                     1.2.0\r\n",
      "update                        0.0.1\r\n",
      "urllib3                       1.26.16\r\n",
      "w3lib                         1.21.0\r\n",
      "watchdog                      2.1.6\r\n",
      "wcwidth                       0.2.5\r\n",
      "webencodings                  0.5.1\r\n",
      "websocket-client              0.58.0\r\n",
      "websockets                    10.4\r\n",
      "Werkzeug                      3.0.1\r\n",
      "whatthepatch                  1.0.2\r\n",
      "wheel                         0.38.4\r\n",
      "widgetsnbextension            4.0.5\r\n",
      "wordcloud                     1.9.3\r\n",
      "wrapt                         1.14.1\r\n",
      "wsproto                       1.2.0\r\n",
      "wurlitzer                     3.0.2\r\n",
      "xarray                        2023.6.0\r\n",
      "xgboost                       2.0.1\r\n",
      "xlwings                       0.29.1\r\n",
      "xxhash                        2.0.2\r\n",
      "xyzservices                   2022.9.0\r\n",
      "y-py                          0.5.9\r\n",
      "yapf                          0.31.0\r\n",
      "yarl                          1.8.1\r\n",
      "ypy-websocket                 0.8.2\r\n",
      "zict                          2.2.0\r\n",
      "zipp                          3.11.0\r\n",
      "zope.interface                5.4.0\r\n",
      "zstandard                     0.19.0\r\n"
     ]
    }
   ],
   "source": [
    "!pip list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad0d1d66",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
